{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lc_net_phase1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "8b51a6187922e1c805af8ddd20d0a4091ecd17bebcd7deb5956ab101caf2f88f"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d1a8f2a1ea4b4b7ba8717c0e59110340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_99ea60825cc8495e9bd3bb767984987e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_53482b02c91243699457c00876b6a778",
              "IPY_MODEL_801c0e012ced447183dbe62088f1064d",
              "IPY_MODEL_50d47f86dc024cc3a24f65298193198c"
            ]
          }
        },
        "99ea60825cc8495e9bd3bb767984987e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53482b02c91243699457c00876b6a778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5d0561ec63e543f59a6603233d48e028",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Running accuracy: 20.00%, Current val accuracy: 11.00%, :   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d3b6295aa07493f98ff998ab07f2cd9"
          }
        },
        "801c0e012ced447183dbe62088f1064d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5679585dce9f49d38cad4a4d137ba486",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7949caa98fe449f6befcb1e071324f10"
          }
        },
        "50d47f86dc024cc3a24f65298193198c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ec345e1a9b5467f9752922cd40b2e00",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/2000 [03:31&lt;9:02:49, 16.37s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d106fed4d2f4a5e80126a178fff1d3e"
          }
        },
        "5d0561ec63e543f59a6603233d48e028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d3b6295aa07493f98ff998ab07f2cd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5679585dce9f49d38cad4a4d137ba486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7949caa98fe449f6befcb1e071324f10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ec345e1a9b5467f9752922cd40b2e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d106fed4d2f4a5e80126a178fff1d3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Singular-Brain/bindsnet/blob/master/lc_net_phase1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fTSvrK3T_GA"
      },
      "source": [
        "#Notebook setups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXtgP_iEPE0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25505528-3f55-468f-a878-17e1deacf2b7"
      },
      "source": [
        "!pip install -q git+https://github.com/Singular-Brain/bindsnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▊                             | 10 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 120 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 280 kB 60.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 28.5 MB 30 kB/s \n",
            "\u001b[?25h  Building wheel for BindsNET (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW7m3ugEHZP_",
        "outputId": "04d762c9-4869-443f-a0f9-19aa634dff76"
      },
      "source": [
        "!wget https://data.deepai.org/mnist.zip\n",
        "!mkdir -p ../data/MNIST/TorchvisionDatasetWrapper/raw\n",
        "!unzip mnist.zip -d ../data/MNIST/TorchvisionDatasetWrapper/raw/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-25 07:43:29--  https://data.deepai.org/mnist.zip\n",
            "Resolving data.deepai.org (data.deepai.org)... 138.201.36.183\n",
            "Connecting to data.deepai.org (data.deepai.org)|138.201.36.183|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11597176 (11M) [application/x-zip-compressed]\n",
            "Saving to: ‘mnist.zip’\n",
            "\n",
            "mnist.zip           100%[===================>]  11.06M  10.9MB/s    in 1.0s    \n",
            "\n",
            "2021-08-25 07:43:31 (10.9 MB/s) - ‘mnist.zip’ saved [11597176/11597176]\n",
            "\n",
            "Archive:  mnist.zip\n",
            "  inflating: ../data/MNIST/TorchvisionDatasetWrapper/raw/train-labels-idx1-ubyte.gz  \n",
            "  inflating: ../data/MNIST/TorchvisionDatasetWrapper/raw/train-images-idx3-ubyte.gz  \n",
            "  inflating: ../data/MNIST/TorchvisionDatasetWrapper/raw/t10k-images-idx3-ubyte.gz  \n",
            "  inflating: ../data/MNIST/TorchvisionDatasetWrapper/raw/t10k-labels-idx1-ubyte.gz  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXcXvvsXcOlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3531f6c1-3fb9-467e-fd85-911b3454c191"
      },
      "source": [
        "!git clone https://github.com/Singular-Brain/bindsnet/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bindsnet'...\n",
            "remote: Enumerating objects: 10629, done.\u001b[K\n",
            "remote: Counting objects: 100% (1589/1589), done.\u001b[K\n",
            "remote: Compressing objects: 100% (548/548), done.\u001b[K\n",
            "remote: Total 10629 (delta 1126), reused 1467 (delta 1040), pack-reused 9040\u001b[K\n",
            "Receiving objects: 100% (10629/10629), 60.91 MiB | 34.84 MiB/s, done.\n",
            "Resolving deltas: 100% (6852/6852), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFGNAecpT-Lj"
      },
      "source": [
        "from bindsnet.network.nodes import Nodes\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "from torchvision import transforms\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Union, Tuple, Optional, Sequence\n",
        "from torch.nn.modules.utils import _pair\n",
        "\n",
        "from bindsnet.datasets import MNIST\n",
        "from bindsnet.encoding import PoissonEncoder\n",
        "from bindsnet.network import Network\n",
        "from bindsnet.network.nodes import Input, LIFNodes, AdaptiveLIFNodes\n",
        "from bindsnet.network.topology import LocalConnection, Connection\n",
        "from bindsnet.network.monitors import Monitor, AbstractMonitor, TensorBoardMonitor\n",
        "from bindsnet.learning import PostPre, MSTDP, MSTDPET, WeightDependentPostPre, Hebbian\n",
        "from bindsnet.learning.reward import DynamicDopamineInjection, DopaminergicRPE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULGGHW43UksI"
      },
      "source": [
        "## Sets up Gpu use and manual seed\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiUmFrpcUfmR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fcc358-0870-4d96-dd4f-02aab0eb0453"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device =  torch.device(\"cuda\")\n",
        "    gpu = True\n",
        "else:\n",
        "    device =  torch.device(\"cpu\")\n",
        "    gpu = False\n",
        "\n",
        "def manual_seed(seed):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "SEED = 2045 # The Singularity is Near!\n",
        "manual_seed(SEED)\n",
        "\n",
        "torch.set_num_threads(os.cpu_count() - 1)\n",
        "print(\"Running on Device = \", device)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on Device =  cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBKedMpIleMr"
      },
      "source": [
        "# Custom Monitors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tfqpsr2a1WV"
      },
      "source": [
        "## Reward Monitor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M44GJ65GleMs"
      },
      "source": [
        "class RewardMonitor(AbstractMonitor):\n",
        "    # language=rst\n",
        "    \"\"\"\n",
        "    Records state variables of interest.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        time: None,\n",
        "        batch_size: int = 1,\n",
        "        device: str = \"cpu\",\n",
        "    ):\n",
        "        # language=rst\n",
        "        \"\"\"\n",
        "        Constructs a ``Monitor`` object.\n",
        "\n",
        "        :param obj: An object to record state variables from during network simulation.\n",
        "        :param state_vars: Iterable of strings indicating names of state variables to record.\n",
        "        :param time: If not ``None``, pre-allocate memory for state variable recording.\n",
        "        :param device: Allow the monitor to be on different device separate from Network device\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.time = time\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device\n",
        "\n",
        "        # if time is not specified the monitor variable accumulate the logs\n",
        "        if self.time is None:\n",
        "            self.device = \"cpu\"\n",
        "\n",
        "        self.recording = []\n",
        "        self.reset_state_variables()\n",
        "\n",
        "    def get(self,) -> torch.Tensor:\n",
        "        # language=rst\n",
        "        \"\"\"\n",
        "        Return recording to user.\n",
        "\n",
        "        :return: Tensor of shape ``[time, n_1, ..., n_k]``, where ``[n_1, ..., n_k]`` is the shape of the recorded state\n",
        "        variable.\n",
        "        Note, if time == `None`, get return the logs and empty the monitor variable\n",
        "\n",
        "        \"\"\"\n",
        "        # return_logs = torch.as_tensor(self.recording)\n",
        "        # if self.time is None:\n",
        "        #     self.recording = []\n",
        "        return self.recording\n",
        "\n",
        "    def record(self, **kwargs) -> None:\n",
        "        # language=rst\n",
        "        \"\"\"\n",
        "        Appends the current value of the recorded state variables to the recording.\n",
        "        \"\"\"\n",
        "        if \"reward\" in kwargs:\n",
        "            self.recording.append(kwargs[\"reward\"])\n",
        "        # remove the oldest element (first in the list)\n",
        "        # if self.time is not None:\n",
        "        #     self.recording.pop(0)\n",
        "\n",
        "    def reset_state_variables(self) -> None:\n",
        "        # language=rst\n",
        "        \"\"\"\n",
        "        Resets recordings to empty ``List``s.\n",
        "        \"\"\"\n",
        "        self.recording = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8clxN_npa1WY"
      },
      "source": [
        "## Plot Eligibility trace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SshGlRwpa1WZ"
      },
      "source": [
        "class PlotET(AbstractMonitor):\n",
        "    # language=rst\n",
        "    \"\"\"\n",
        "    Records state variables of interest.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        i,\n",
        "        j,\n",
        "        source,\n",
        "        target,\n",
        "        connection,\n",
        "    ):\n",
        "        # language=rst\n",
        "        \"\"\"\n",
        "        Constructs a ``Monitor`` object.\n",
        "\n",
        "        :param obj: An object to record state variables from during network simulation.\n",
        "        :param state_vars: Iterable of strings indicating names of state variables to record.\n",
        "        :param time: If not ``None``, pre-allocate memory for state variable recording.\n",
        "        :param device: Allow the monitor to be on different device separate from Network device\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.i = i\n",
        "        self.j = j\n",
        "        self.source = source\n",
        "        self.target = target\n",
        "        self.connection = connection\n",
        "\n",
        "        self.reset_state_variables()\n",
        "\n",
        "    def get(self,) -> torch.Tensor:\n",
        "        # language=rst\n",
        "        \"\"\"\n",
        "        Return recording to user.\n",
        "\n",
        "        :return: Tensor of shape ``[time, n_1, ..., n_k]``, where ``[n_1, ..., n_k]`` is the shape of the recorded state\n",
        "        variable.\n",
        "        Note, if time == `None`, get return the logs and empty the monitor variable\n",
        "\n",
        "        \"\"\"\n",
        "        # return_logs = torch.as_tensor(self.recording)\n",
        "        # if self.time is None:\n",
        "        #     self.recording = []\n",
        "        return self.recording\n",
        "\n",
        "    def record(self, **kwargs) -> None:\n",
        "        # language=rst\n",
        "        \"\"\"\n",
        "        Appends the current value of the recorded state variables to the recording.\n",
        "        \"\"\"\n",
        "        if hasattr(self.connection.update_rule, 'p_plus'):\n",
        "            self.recording['spikes_i'].append(self.source.s.ravel()[self.i].item())\n",
        "            self.recording['spikes_j'].append(self.target.s.ravel()[self.j].item())\n",
        "            self.recording['p_plus'].append(self.connection.update_rule.p_plus[self.i].item())\n",
        "            self.recording['p_minus'].append(self.connection.update_rule.p_minus[self.j].item())\n",
        "            self.recording['eligibility'].append(self.connection.update_rule.eligibility[self.i,self.j].item())\n",
        "            self.recording['eligibility_trace'].append(self.connection.update_rule.eligibility_trace[self.i,self.j].item())\n",
        "            self.recording['w'].append(self.connection.w[self.i,self.j].item())\n",
        "\n",
        "    def plot(self):\n",
        "\n",
        "        fig, axs  = plt.subplots(7)\n",
        "        fig.set_size_inches(10, 20)\n",
        "        for i, (name, p) in enumerate(self.recording.items()):\n",
        "            axs[i].plot(p[-250:])\n",
        "            axs[i].set_title(name)\n",
        "    \n",
        "        fig.show()\n",
        "\n",
        "    def reset_state_variables(self) -> None:\n",
        "        # language=rst\n",
        "        \"\"\"\n",
        "        Resets recordings to empty ``List``s.\n",
        "        \"\"\"\n",
        "        self.recording = {\n",
        "        'spikes_i': [],\n",
        "        'spikes_j': [],\n",
        "        'p_plus':[],\n",
        "        'p_minus':[],\n",
        "        'eligibility':[],\n",
        "        'eligibility_trace':[],\n",
        "        'w': [],\n",
        "        }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL0giSqUUvz6"
      },
      "source": [
        "# Design network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6ug54P679DF"
      },
      "source": [
        "compute_size = lambda inp_size, k, s: int((inp_size-k)/s) + 1\n",
        "\n",
        "class LCNet(Network):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_classes: int,\n",
        "        neuron_per_class: int,\n",
        "        n_channels:int,\n",
        "        filter_size: int,\n",
        "        stride: int,\n",
        "        online: bool,\n",
        "        time: int,\n",
        "        reward_fn,\n",
        "        n_neurons: int,\n",
        "        pre_observation: bool,\n",
        "        has_decision_period: bool,\n",
        "        local_rewarding: bool,\n",
        "        nu_LC: Union[float, Tuple[float, float]],\n",
        "        nu_Output: float,\n",
        "        dt: float = 1.0,\n",
        "        crop_size:int = 20,\n",
        "        nu_inh_LC: float=0.01,\n",
        "        nu_inh: float=0.0,\n",
        "        inh_type = None,\n",
        "        inh_LC: bool=False,\n",
        "        inh_factor_LC: float=100,\n",
        "        inh_factor:float = 0.25,\n",
        "        single_output_layer:bool = False,\n",
        "        NodesType_LC = LIFNodes,\n",
        "        NodesType_Output = AdaptiveLIFNodes, \n",
        "        update_rule_LC = PostPre,\n",
        "        update_rule_Output = MSTDPET,\n",
        "        update_rule_inh = PostPre,\n",
        "        update_rule_inh_LC = PostPre,\n",
        "        wmin: float = 0.0,\n",
        "        wmax: float = 1.0,\n",
        "        soft_bound = False,\n",
        "        theta_plus: float = 2.0,\n",
        "        tc_theta_decay: float = 250,\n",
        "        tc_trace:int = 20,\n",
        "        normal_init:bool = False,\n",
        "        mu: float=0.5,\n",
        "        std:float=0.01,\n",
        "        norm_factor_inh_LC: bool= None,\n",
        "        norm_factor_LC = None,\n",
        "        norm_factor_out = None,\n",
        "        norm_factor_inh = None,\n",
        "        trace_additive = False,\n",
        "        load_path = None,\n",
        "        save_path = None,\n",
        "        confusion_matrix = False,\n",
        "        **kwargs,\n",
        "    ) -> None:\n",
        "        # language=rst\n",
        "        \"\"\"\n",
        "        Constructor for class ``BioLCNet``.\n",
        "\n",
        "        :param n_inpt: Number of input neurons. Matches the 1D size of the input data.\n",
        "        :param n_neurons: Number of excitatory, inhibitory neurons.\n",
        "        :param exc: Strength of synapse weights from excitatory to inhibitory layer.\n",
        "        :param inh: Strength of synapse weights from inhibitory to excitatory layer.\n",
        "        :param dt: Simulation time step.\n",
        "        :param nu: Single or pair of learning rates for pre- and post-synaptic events,\n",
        "            respectively.\n",
        "        :param reduction: Method for reducing parameter updates along the minibatch\n",
        "            dimension.\n",
        "        :param wmin: Minimum allowed weight on input to excitatory synapses.\n",
        "        :param wmax: Maximum allowed weight on input to excitatory synapses.\n",
        "        :param norm: Input to excitatory layer connection weights normalization\n",
        "            constant.\n",
        "        :param theta_plus: On-spike increment of ``(adaptive)LIFNodes`` membrane\n",
        "            threshold potential.\n",
        "        :param tc_theta_decay: Time constant of ``(adaptive)LIFNodes`` threshold\n",
        "            potential decay.\n",
        "        :param inpt_shape: The dimensionality of the input layer.\n",
        "        \"\"\"\n",
        "        manual_seed(SEED)\n",
        "        super().__init__(dt=dt, reward_fn = None, online=online)\n",
        "        kwargs['single_output_layer'] = single_output_layer\n",
        "        kwargs['dt'] = dt\n",
        "        kwargs['n_labels'] = n_classes\n",
        "        kwargs['neuron_per_class'] = neuron_per_class\n",
        "        \n",
        "\n",
        "        self.reward_fn = reward_fn(**kwargs)\n",
        "        self.reward_fn.network = self\n",
        "        self.reward_fn.dt = self.dt\n",
        "        self.n_classes = n_classes\n",
        "        self.neuron_per_class = neuron_per_class\n",
        "        self.save_path = save_path\n",
        "        self.load_path = load_path\n",
        "        self.dt = dt\n",
        "        self.time = time\n",
        "        self.clamp = kwargs['clamp']\n",
        "        self.single_output_layer = single_output_layer\n",
        "        self.pre_observation = pre_observation\n",
        "        self.has_decision_period = has_decision_period\n",
        "        self.local_rewarding = local_rewarding\n",
        "        self.soft_bound = soft_bound\n",
        "        self.confusion_matrix = confusion_matrix\n",
        "\n",
        "        if kwargs['variant'] == 'scalar':\n",
        "            assert self.has_decision_period == True, ''\n",
        "\n",
        "        if self.online == False:\n",
        "            assert self.has_decision_period == True, ''\n",
        "        \n",
        "        if self.has_decision_period == True:\n",
        "            assert self.online == False, \"Decision period is not compatible with online learning.\"\n",
        "            self.observation_period = kwargs['observation_period']\n",
        "            assert self.observation_period >= 0, \"\"\n",
        "            self.decision_period = kwargs['decision_period']\n",
        "            assert self.decision_period > 0, \"\"\n",
        "            self.learning_period = self.time - self.observation_period - self.decision_period\n",
        "\n",
        "        elif self.pre_observation == True:\n",
        "            self.observation_period = kwargs['observation_period']\n",
        "            assert self.observation_period >= 0, \"\"\n",
        "            self.learning_period = self.time - self.observation_period\n",
        "            self.decision_period = self.time - self.observation_period\n",
        "\n",
        "        else:\n",
        "            self.observation_period = 0\n",
        "            self.decision_period = self.time\n",
        "            self.learning_period = self.time\n",
        "\n",
        "        ### nodes\n",
        "        inp = Input(shape= [1,20,20], traces=True, tc_trace=tc_trace,traces_additive = trace_additive)\n",
        "        self.add_layer(inp, name=\"input\")\n",
        "        main = NodesType_LC(shape= [n_channels, compute_size(crop_size, filter_size, stride), \n",
        "                                        compute_size(crop_size, filter_size, stride)], \n",
        "                                        traces=True, tc_trace=tc_trace,traces_additive = trace_additive,\n",
        "                                        tc_theta_decay = tc_theta_decay, theta_plus = theta_plus)\n",
        "        \n",
        "        self.add_layer(main, name=\"main\")\n",
        "        ### connections \n",
        "        if mu == None:\n",
        "            mu = (wmin + wmax) / 2\n",
        "        if std == None:\n",
        "            std = (wmax - wmin) / 8\n",
        "        LC = LocalConnection(inp, main, filter_size, stride, n_channels, nu = _pair(nu_LC), update_rule = update_rule_LC,wmin = wmin, wmax= wmax, soft_bound = soft_bound, norm = norm_factor_LC)\n",
        "        if normal_init:\n",
        "            w_lc_init = torch.normal(mu,std,size = (inp.n,main.n))\n",
        "            LC.w.data = w_lc_init.masked_fill(LC.mask,0)\n",
        "        self.add_connection(LC, \"input\", \"main\")\n",
        "\n",
        "        if inh_LC:\n",
        "            main_width = compute_size(crop_size, filter_size, stride)\n",
        "            w_inh_LC = torch.zeros(n_channels,main_width,main_width,n_channels,main_width,main_width)\n",
        "            for c in range(n_channels):\n",
        "                for w1 in range(main_width):\n",
        "                    for w2 in range(main_width):\n",
        "                        w_inh_LC[c,w1,w2,:,w1,w2] = - inh_factor_LC\n",
        "                        w_inh_LC[c,w1,w2,c,w1,w2] = 0\n",
        "        \n",
        "            w_inh_LC = w_inh_LC.reshape(main.n,main.n)\n",
        "                                                             \n",
        "            LC_recurrent_inhibition = Connection(\n",
        "                source=main,\n",
        "                target=main,\n",
        "                w=w_inh_LC,\n",
        "            )\n",
        "            self.add_connection(LC_recurrent_inhibition, \"main\", \"main\")\n",
        "\n",
        "        ### main to output\n",
        "        if single_output_layer:\n",
        "            out = NodesType_Output(n= n_neurons, traces=True,traces_additive = trace_additive, tc_trace=tc_trace, tc_theta_decay = tc_theta_decay, theta_plus = theta_plus)\n",
        "            self.add_layer(out, \"output\")\n",
        "            main_out = Connection(main, out, nu = nu_Output, update_rule = update_rule_Output, wmin = wmin, wmax= wmax, norm = norm_factor_out)\n",
        "            if normal_init:\n",
        "                w_main_init = torch.normal(mu,std,size = (main.n,out.n)) \n",
        "                main_out.w.data = w_main_init\n",
        "                \n",
        "            self.add_connection(main_out, \"main\", \"output\")\n",
        "            ### Inhibitory:\n",
        "            if inh_type == 'between_layers':\n",
        "                w = -inh_factor * torch.ones(out.n, out.n)\n",
        "                for c in range(n_classes):\n",
        "                    ind = slice(c*neuron_per_class,(c+1)*neuron_per_class)\n",
        "                    w[ind, ind] = 0\n",
        "\n",
        "                out_recurrent_inhibition = Connection(\n",
        "                    source=out,\n",
        "                    target=out,\n",
        "                    w=w,\n",
        "                    update_rule = update_rule_inh,\n",
        "                    wmin=-inh_factor,\n",
        "                    wmax=0,\n",
        "                    nu = nu_inh,\n",
        "                    norm = norm_factor_inh,\n",
        "                )\n",
        "                self.add_connection(out_recurrent_inhibition, \"output\", \"output\")\n",
        "\n",
        "            # Diehl and Cook\n",
        "            elif inh_type == 'DC':\n",
        "                raise NotImplementedError('Diehl and cook not implemented yet fo r 10 classes')\n",
        "\n",
        "        # else:   \n",
        "        #     for c in range(n_classes):\n",
        "        #         self.add_layer(\n",
        "        #             NodesType_Output(n= neuron_per_class, traces=True, tc_trace=tc_trace,\n",
        "        #                             #adpativeLIF_parameters\n",
        "        #                             tc_theta_decay = tc_theta_decay, theta_plus = theta_plus),\n",
        "        #             name=f\"output_{c}\",\n",
        "        #         )\n",
        "\n",
        "        #         self.add_connection(\n",
        "        #             Connection(\n",
        "        #                 main,\n",
        "        #                 self.layers[f\"output_{c}\"],\n",
        "        #                 update_rule = update_rule_Output,\n",
        "        #                 nu = nu_inh,\n",
        "        #                 wmin = wmin, \n",
        "        #                 wmax= wmax,\n",
        "        #                 norm = norm_factor_inh,\n",
        "        #             ),\n",
        "        #             \"main\",\n",
        "        #             f\"output_{c}\",\n",
        "        #         )\n",
        "\n",
        "\n",
        "        #     ### Inhibitory:\n",
        "        #     if inh_type == 'between_layers':\n",
        "        #         for source in range(n_classes):\n",
        "        #             for target in range(n_classes):\n",
        "        #                 if source == target:\n",
        "        #                     continue\n",
        "        #                 self.add_connection(\n",
        "        #                     Connection(\n",
        "        #                         self.layers[f\"output_{source}\"],\n",
        "        #                         self.layers[f\"output_{target}\"],\n",
        "        #                         update_rule = update_rule_inh,\n",
        "        #                         nu = nu_inh,\n",
        "        #                         wmin=-inh_factor,\n",
        "        #                         wmax=0,\n",
        "        #                         w= torch.ones(\n",
        "        #                             self.layers[f\"output_{source}\"].n,\n",
        "        #                             self.layers[f\"output_{target}\"].n,\n",
        "        #                         ) * -inh_factor,\n",
        "        #                         norm=norm_factor_inh,\n",
        "        #                     ),\n",
        "        #                     f\"output_{source}\",\n",
        "        #                     f\"output_{target}\",\n",
        "        #                 )\n",
        "        #     elif inh_type == 'DC':\n",
        "        #         inh_layer = NodesType(n= n_neurons, traces=True, tc_trace=tc_trace)\n",
        "        #         self.add_layer(inh_layer, name=\"inh\")\n",
        "        #         for out_layer in range(n_classes):\n",
        "        #             self.add_connection(\n",
        "        #                     Connection(\n",
        "        #                         self.layers[f\"output_{out_layer}\"],\n",
        "        #                         inh_layer,\n",
        "        #                         update_rule = update_rule_inh,\n",
        "        #                         nu = nu_inh,\n",
        "        #                         wmin = 0,\n",
        "        #                         wmax=wmax,\n",
        "        #                         norm = norm_factor_inh,\n",
        "        #                     ),\n",
        "        #                     f\"output_{out_layer}\",\n",
        "        #                     \"inh\",\n",
        "        #                 )\n",
        "        #             self.add_connection(\n",
        "        #                     Connection(\n",
        "        #                         inh_layer,\n",
        "        #                         self.layers[f\"output_{out_layer}\"],\n",
        "        #                         update_rule = update_rule_inh,\n",
        "        #                         nu = nu,\n",
        "        #                         wmin = wmin,\n",
        "        #                         wmax=0,\n",
        "        #                         norm = norm_factor_inh,\n",
        "        #                     ),\n",
        "        #                     \"inh\",\n",
        "        #                     f\"output_{out_layer}\",\n",
        "        #                 ) \n",
        "\n",
        "        # Directs network to GPU\n",
        "\n",
        "        if gpu:\n",
        "            self.to(\"cuda\")\n",
        "\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        dataloader,\n",
        "        val_loader,\n",
        "        reward_hparams,\n",
        "        hparams = None,\n",
        "        online_validate = True,\n",
        "        n_train = 2000,\n",
        "        n_test = 250,\n",
        "        n_val = 250,\n",
        "        val_interval = 250,\n",
        "        running_window_length = 250,\n",
        "        verbose = True,\n",
        "    ):\n",
        "        manual_seed(SEED)\n",
        "        self.verbose = verbose\n",
        "        # add Monitors\n",
        "        main_monitor = Monitor(self.layers[\"main\"], [\"v\"], time=None, device=device)\n",
        "        reward_monitor = RewardMonitor(time =self.time)\n",
        "        #Plot_et = PlotET(i = 0, j = 0, source = self.layers[\"main\"], target = self.layers[\"output\"], connection = self.connections[(\"main\",\"output\")])\n",
        "        tensorboard = TensorBoardMonitor(self, time = self.time)\n",
        "        self.add_monitor(main_monitor, name=\"main\")\n",
        "        self.add_monitor(reward_monitor, name=\"reward\")\n",
        "        #self.add_monitor(Plot_et, name=\"Plot_et\")\n",
        "        self.add_monitor(tensorboard, name=\"tensorboard\")\n",
        "\n",
        "            \n",
        "        acc_hist = collections.deque([], running_window_length)\n",
        "\n",
        "        #if self.single_output_layer:\n",
        "        self.spikes = {}\n",
        "        for layer in set(self.layers):\n",
        "            self.spikes[layer] = Monitor(self.layers[layer], state_vars=[\"s\"], time=None)\n",
        "            self.add_monitor(self.spikes[layer], name=\"%s_spikes\" % layer)\n",
        "            self.dopaminergic_layers = self.layers[\"output\"]\n",
        "        # else:\n",
        "        #     output_layers = set([layer for layer in self.layers if layer.startswith('output')])\n",
        "        #     self.output_spikes = {}\n",
        "        #     for layer in output_layers:\n",
        "        #         self.output_spikes[layer] = Monitor(self.layers[layer], state_vars=[\"s\"], time=self.time)\n",
        "        #         self.add_monitor(self.output_spikes[layer], name=\"%s_spikes\" % layer)\n",
        "        #         self.dopaminergic_layers = {name: layer for name, layer in self.layers.items() if name.startswith('output')}\n",
        "\n",
        "        val_acc = 0.0\n",
        "\n",
        "        reward_history = []\n",
        "        if self.load_path:\n",
        "            # try:\n",
        "            self.model_params = torch.load(self.load_path)\n",
        "            self.load_state_dict(torch.load(self.load_path)['state_dict'])\n",
        "            iteration =  self.model_params['iteration']\n",
        "            hparams = self.model_params['hparams']\n",
        "            train_accs = self.model_params['train_accs']\n",
        "            val_accs = self.model_params['val_accs']\n",
        "            acc_rewards = self.model_params['acc_rewards']\n",
        "            print(f'Previous model loaded! Resuming training from iteration {iteration}..., last running training accuracy: {train_accs[-1]}, last validation accuracy: {val_accs[-1]}\\n') if self.verbose else None\n",
        "        else:\n",
        "            print(f'Previous model not found! Training from the beginning...\\n') if self.verbose else None\n",
        "            val_accs = []\n",
        "            train_accs = []\n",
        "            acc_rewards = []\n",
        "            # except:\n",
        "            #     pass\n",
        "        pbar = tqdm(total=n_train)\n",
        "        self.reset_state_variables()\n",
        "\n",
        "\n",
        "\n",
        "        for (i, datum) in enumerate(dataloader):\n",
        "            if self.load_path:\n",
        "                #try:\n",
        "                if i <= iteration:\n",
        "                    n_train += 1\n",
        "                    continue\n",
        "                # except:\n",
        "                #     pass\n",
        "            if i > n_train:\n",
        "                break\n",
        "\n",
        "\n",
        "            image = datum[\"encoded_image\"]\n",
        "            label = datum[\"label\"]\n",
        "\n",
        "            # Run the network on the input.\n",
        "            if gpu:\n",
        "                inputs = {\"input\": image.cuda().view(self.time, 1, 1, 20, 20)}\n",
        "            else:\n",
        "                inputs = {\"input\": image.view(self.time, 1, 1, 20, 20)}\n",
        "            #print(self.spikes['output'].get('s'))\n",
        "\n",
        "            self.run(inputs=inputs, \n",
        "                    time=self.time, \n",
        "                    **reward_hparams,\n",
        "                    true_label = label.int().item(),\n",
        "                    dopaminergic_layers= self.dopaminergic_layers,\n",
        "                    clamp = self.clamp\n",
        "                     )\n",
        "            # print(self.layers['output'].theta_plus)\n",
        "            # print(self.layers['output'].theta)\n",
        "            #print(self.connections[('input', 'main')].w.sum(axis=0))\n",
        "\n",
        "\n",
        "            # Get voltage recording.\n",
        "            main_voltage = main_monitor.get(\"v\")\n",
        "            reward_history.append(reward_monitor.get())\n",
        "            tensorboard.update(step= i)\n",
        "            # Add to spikes recording.\n",
        "            #if self.single_output_layer:\n",
        "            #print(self.monitors['output_spikes'].get('s').shape)\n",
        "            lc_spikes = self.spikes['main'].get('s')\n",
        "            out_spikes = self.spikes[\"output\"].get(\"s\").view(self.time, n_classes, neuron_per_class)\n",
        "            sum_spikes = out_spikes[self.observation_period:self.observation_period+self.decision_period,:,:].sum(0).sum(1)\n",
        "            predicted_label = torch.argmax(sum_spikes)\n",
        "            # else:\n",
        "            #     spikes_record = torch.zeros(self.n_classes, self.time, self.neuron_per_class)\n",
        "            #     for c in range(self.n_classes):\n",
        "            #         spikes_record[c] = self.output_spikes[f\"output_{c}\"].get(\"s\").squeeze(1)\n",
        "            #     sum_spikes = spikes_record.sum(1).sum(1)\n",
        "            #     predicted_label = torch.argmax(sum_spikes)    \n",
        "\n",
        "            if predicted_label == label:\n",
        "                # if reward_hparams['two_pass']:\n",
        "                #     reward_hparams['dopamine_for_correct_pred'] = 0.1\n",
        "                #     print(' => Second pass with dopamine_for_correct_pred:', reward_hparams['dopamine_for_correct_pred'], end = '')\n",
        "                #     self.run(inputs=inputs, time=self.time, **reward_hparams, labels =  label.int().item(),dopaminergic_layers= dopaminergic_layers)\n",
        "                acc_hist.append(1)\n",
        "            else:\n",
        "                # if reward_hparams['two_pass']:\n",
        "                #     reward_hparams['dopamine_for_correct_pred'] = 0.0\n",
        "                #     print(' => Second pass with dopamine_for_correct_pred:', reward_hparams['dopamine_for_correct_pred'], end = '')\n",
        "                #     self.run(inputs=inputs, time=self.time, **reward_hparams, labels =  label.int().item(),dopaminergic_layers= dopaminergic_layers, train=True)\n",
        "                acc_hist.append(0)\n",
        "\n",
        "            #reward_hparams['dopamine_for_correct_pred'] = 0.0\n",
        "            w_lc = self.connections[('input', 'main')].w\n",
        "            w_main_out = self.connections[('main','output')].w\n",
        "            #w_inh = self.connections[('output','output')].w\n",
        "\n",
        "            print(\"\\routput\", sum_spikes, 'pred_label:',\n",
        "                predicted_label.item(), 'GT:', label.item(),\n",
        "                ', Acc Rew:', round(sum(reward_monitor.get()).item(),4),\n",
        "                f\"Pos dps: {self.reward_fn.dps:.5f}, Neg dps: {self.reward_fn.neg_dps:.5f}, Rew base: {self.reward_fn.rew_base:.5f}, Pun base: {self.reward_fn.punish_base:.5f}, RPe: {self.reward_fn.reward_predict_episode:.3f}\",\n",
        "                f\"input_mean_fire_freq: {torch.mean(image.float())*1000:.1f},main_mean_fire_freq:{torch.mean(lc_spikes.float())*1000:.1f}\",\n",
        "                f\"output_mean_fire_freq:{torch.mean(out_spikes.float())*1000:.1f}\",\n",
        "                f\"mean_lc_w: {torch.mean(w_lc[w_lc!=0]):.5f}, mean_fc_w:{torch.mean(w_main_out[w_main_out!=0]):.5f}\",\n",
        "                f\"std_lc_w: {torch.std(w_lc[w_lc!=0]):.5f},std_fc_w:{torch.std(w_main_out[w_main_out!=0]):.5f}\",\n",
        "                end = '')\n",
        "\n",
        "  \n",
        "            acc = 100 * sum(acc_hist)/len(acc_hist)\n",
        "            self.reward_fn.update(accumulated_reward= sum(reward_monitor.get()), ema_window = reward_hparams['ema_window']) \n",
        "\n",
        "            if online_validate and i % val_interval == 0 and i!=0:\n",
        "                self.reset_state_variables()\n",
        "                val_acc = self.evaluate(val_loader, n_val, val_interval, running_window_length)\n",
        "                tensorboard.writer.add_scalars(\"accuracy\", {\"train\": acc, \"val\" : val_acc}, i)\n",
        "                train_accs.append(acc)\n",
        "                val_accs.append(val_acc)\n",
        "                acc_rewards.append(sum(reward_monitor.get()))\n",
        "                if self.save_path is not None:\n",
        "                    model_params = {'state_dict': self.state_dict(), 'hparams': hparams, 'iteration': i, 'val_accs': val_accs, 'train_accs': train_accs, 'acc_rewards': acc_rewards}\n",
        "                    torch.save(model_params, self.save_path)\n",
        "            else:\n",
        "                tensorboard.writer.add_scalars(\"accuracy\", {\"train\": acc}, i)\n",
        "            tensorboard.writer.add_scalar(\"reward\", sum(reward_monitor.get()), i)\n",
        "\n",
        "            # if  i % val_interval == 0 and i!=0:\n",
        "            #     fig = create_plot(self.output_spikes, reward_monitor.get(), label)\n",
        "            #     tensorboard.writer.add_figure('reward', fig, i)\n",
        "            \n",
        "            #Plot_et.plot()    \n",
        "            self.reset_state_variables()  # Reset state variables.\n",
        "            \n",
        "            pbar.set_description_str(\"Running accuracy: \" + \"{:.2f}\".format(acc) + \"%, \" + \"Current val accuracy: \" + \"{:.2f}\".format(val_acc) + \"%, \")\n",
        "            pbar.update()\n",
        "\n",
        "        result_metrics = {'train_acc': acc, 'val_acc': val_acc}\n",
        "        tensorboard.writer.add_hparams(\n",
        "            {k:(v if type(v) in (int, float, bool, str, torch.Tensor) else str(v)) for k,v in {**train_hparams, **data_hparams, **network_hparams, **reward_hparams}.items() },\n",
        "            result_metrics\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def evaluate(self, val_loader, n_val, val_interval, running_window_length):\n",
        "        manual_seed(SEED)\n",
        "        acc_hist_val = collections.deque([], running_window_length)\n",
        "\n",
        "        spikes_val = {}\n",
        "\n",
        "        self.train(False)\n",
        "        self.learning = False\n",
        "\n",
        "        GT, y_pred = [], []\n",
        "        for (i, datum) in enumerate(val_loader):\n",
        "            if i > n_val:\n",
        "                break\n",
        "\n",
        "            image = datum[\"encoded_image\"]\n",
        "            label = datum[\"label\"]\n",
        "\n",
        "            # Run the network on the input.\n",
        "            if gpu:\n",
        "                inputs = {\"input\": image.cuda().view(self.time, 1, 1, 20, 20)}\n",
        "            else:\n",
        "                inputs = {\"input\": image.view(self.time, 1, 1, 20, 20)}\n",
        "\n",
        "            self.run(inputs=inputs, \n",
        "                    time=self.time, \n",
        "                    **reward_hparams,\n",
        "                    true_label = label.int().item(),\n",
        "                    dopaminergic_layers= self.dopaminergic_layers,\n",
        "                     )\n",
        "            # Add to spikes recording.\n",
        "            #if self.single_output_layer:\n",
        "            out_spikes = self.spikes[\"output\"].get(\"s\").view(self.time, n_classes, neuron_per_class)\n",
        "            sum_spikes = out_spikes[self.observation_period:self.observation_period+self.decision_period,:,:].sum(0).sum(1)\n",
        "            predicted_label = torch.argmax(sum_spikes)\n",
        "            # else:\n",
        "            #     spikes_record = torch.zeros(self.n_classes, self.time, self.neuron_per_class)\n",
        "            #     for c in range(self.n_classes):\n",
        "            #         spikes_record[c] = self.output_spikes[f\"output_{c}\"].get(\"s\").squeeze(1)\n",
        "            #     sum_spikes = spikes_record.sum(1).sum(1)\n",
        "            #     predicted_label = torch.argmax(sum_spikes)\n",
        "\n",
        "            if predicted_label == label:\n",
        "                acc_hist_val.append(1)\n",
        "            else:\n",
        "                acc_hist_val.append(0)\n",
        "            \n",
        "            GT.append(label)\n",
        "            y_pred.append(predicted_label)\n",
        "            \n",
        "            print(\"\\r*validation: output\",sum_spikes,\n",
        "                'predicted_label:', predicted_label.item(), 'GT:', label.item(),\n",
        "                end = '') if self.verbose else None\n",
        "            \n",
        "            self.reset_state_variables()  # Reset state variables.\n",
        "\n",
        "        if self.confusion_matrix:\n",
        "            self.plot_confusion_matrix(GT, y_pred)\n",
        "        self.train(True)\n",
        "        self.learning = True\n",
        "        val_acc = 100 * sum(acc_hist_val)/len(acc_hist_val)\n",
        "        return val_acc\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_confusion_matrix(GT, y_predicted):\n",
        "        cm = confusion_matrix(GT, y_predicted)\n",
        "        plt.figure(figsize = (10,7))\n",
        "        sn.heatmap(cm, annot=True)\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Truth')\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zuUBU9pU3vE"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DW7dB11jdqi"
      },
      "source": [
        "class ClassSelector(torch.utils.data.sampler.Sampler):\n",
        "    \"\"\"Select target classes from the dataset\"\"\"\n",
        "    def __init__(self, target_classes, data_source, mask = None):\n",
        "        if mask is not None:\n",
        "            self.mask = mask\n",
        "        else:\n",
        "            self.mask = torch.tensor([1 if data_source[i]['label'] in target_classes else 0 for i in range(len(data_source))])\n",
        "        self.data_source = data_source\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter([i.item() for i in torch.nonzero(self.mask)])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_source)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlCXBY0DU3Mc"
      },
      "source": [
        "# Load MNIST data.\n",
        "def load_datasets(network_hparams, data_hparams, mask=None, test_mask=None):\n",
        "    manual_seed(SEED)\n",
        "    dataset = MNIST(\n",
        "        PoissonEncoder(time=network_hparams['time'], dt=network_hparams['dt']),\n",
        "        None,\n",
        "        root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda x: (\n",
        "                x.round() if data_hparams['round_input'] else x\n",
        "            ) * data_hparams['intensity']),\n",
        "            transforms.CenterCrop(data_hparams['crop_size'])]\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Create a dataloader to iterate and batch data\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1,\n",
        "                                            sampler = ClassSelector(\n",
        "                                                    target_classes = target_classes,\n",
        "                                                    data_source = dataset,\n",
        "                                                    mask = mask,\n",
        "                                                    ) if target_classes else None\n",
        "                                            )\n",
        "\n",
        "    # Load test dataset\n",
        "    test_dataset = MNIST(   \n",
        "        PoissonEncoder(time=network_hparams['time'], dt=network_hparams['dt']),\n",
        "        None,\n",
        "        root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
        "        download=True,\n",
        "        train=False,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda x: (\n",
        "                x.round() if data_hparams['round_input'] else x\n",
        "            ) * data_hparams['intensity']),\n",
        "            transforms.CenterCrop(data_hparams['crop_size'])]\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1,\n",
        "                                            sampler = ClassSelector(\n",
        "                                                    target_classes = target_classes,\n",
        "                                                    data_source = test_dataset,\n",
        "                                                    mask = mask_test,\n",
        "                                                    ) if target_classes else None\n",
        "                                            )\n",
        "    \n",
        "\n",
        "    return dataloader, val_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCqAFucAUDb8"
      },
      "source": [
        "# Set up hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0Wh_eJIFkO-"
      },
      "source": [
        "train_hparams = {\n",
        "    'n_train' : 3000,\n",
        "    'n_test' : 3000,\n",
        "    'n_val' : 250,\n",
        "    'val_interval' : 500,\n",
        "    'running_window_length': 250,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVOqxcYtFd5T"
      },
      "source": [
        "# Dataset Hyperparameters\n",
        "target_classes = None #(0,1)\n",
        "if target_classes:\n",
        "    npz_file = np.load(f'bindsnet/mask_{\"_\".join([str(i) for i in target_classes])}.npz')\n",
        "    mask, mask_test = torch.from_numpy(npz_file['arr_0']), torch.from_numpy(npz_file['arr_1'])\n",
        "    n_classes = len(target_classes)\n",
        "    \n",
        "else:\n",
        "    mask = None\n",
        "    mask_test = None\n",
        "    n_classes = 10\n",
        "\n",
        "data_hparams = { \n",
        "    'intensity': 64,\n",
        "    'crop_size': 20,\n",
        "    'round_input': True,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TerGeJoFdzg"
      },
      "source": [
        "n_neurons = 100 #100\n",
        "clamping_intensity = None #20\n",
        "neuron_per_class = int(n_neurons/n_classes)\n",
        "single_output_layer = True\n",
        "\n",
        "\n",
        "network_hparams = {\n",
        "    # net structure\n",
        "    'crop_size': 20,\n",
        "    'neuron_per_class': neuron_per_class,\n",
        "    'n_channels': 100,\n",
        "    'filter_size': 12,\n",
        "    'stride': 4,\n",
        "    'n_neurons' : n_neurons,\n",
        "    'n_classes': n_classes,\n",
        "    'single_output_layer': True,\n",
        "    \n",
        "    # time & Phase\n",
        "    'dt' : 1,\n",
        "    'pre_observation': True,\n",
        "    'has_decision_period': False,\n",
        "    'observation_period': 200,\n",
        "    'decision_period': 0,\n",
        "    'online': True,\n",
        "    'local_rewarding': False,\n",
        "    \n",
        "    # Nodes\n",
        "    'NodesType_LC': LIFNodes,\n",
        "    'NodesType_Output': LIFNodes, \n",
        "    'theta_plus': 0.05,\n",
        "    'tc_theta_decay': 0,\n",
        "    'tc_trace':20,\n",
        "    'trace_additive' : False,\n",
        "    \n",
        "    # Learning\n",
        "    'update_rule_LC': PostPre,\n",
        "    'update_rule_Output': MSTDPET,\n",
        "    'update_rule_inh': None,\n",
        "    'update_rule_inh_LC' : None,\n",
        "    'nu_LC': (0.0001,0.01),\n",
        "    'nu_Output':0.1,\n",
        "    'nu_inh': 0.0,\n",
        "    'nu_inh_LC': 0.0,\n",
        "    'soft_bound': False,\n",
        "\n",
        "    # weights\n",
        "    'normal_init': False,\n",
        "    'mean' : 0.5,\n",
        "    'std' : 0.05,\n",
        "    'wmin': 0.0,\n",
        "    'wmax': 1.0,\n",
        "    \n",
        "    # Inhibition\n",
        "    'inh_type': 'between_layers',\n",
        "    'inh_factor': 0.5,\n",
        "    'inh_LC': True,\n",
        "    'inh_factor_LC': 0.5,\n",
        "    \n",
        "    # Normalization\n",
        "    'norm_factor_LC':  0.2*12*12,\n",
        "    'norm_factor_out': None,\n",
        "    'norm_factor_inh': None,\n",
        "    'norm_factor_inh_LC': None,\n",
        "    \n",
        "    # clamp\n",
        "    'clamping_intensity': clamping_intensity,\n",
        "\n",
        "    # metrics\n",
        "    'confusion_matrix': True,\n",
        "\n",
        "    # Save\n",
        "    'save_path': None,#'/content/drive/My Drive/LCNet/LCNet_phase1_baseline_gpu.pth',\n",
        "    'load_path': None,#'content/drive/My Drive/LCNet/LCNet_phase1_baseline_gpu.pth',\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "reward_hparams= {\n",
        "    'n_labels': n_classes,\n",
        "    'neuron_per_class': neuron_per_class,\n",
        "    \n",
        "    'variant': 'pure_per_spike',  #true_pred, #pure_per_spike (Just in phase I, online : True) , and #scalar \n",
        "    'tc_reward':0,\n",
        "    'dopamine_base': 0.001,\n",
        "    'reward_base': 0.01,\n",
        "    'punishment_base': 0.001,\n",
        "    \n",
        "    'sub_variant': 'static', #static, #RPE, #pred_decay\n",
        "    'td_nu': 0.0001,  #RPE\n",
        "    'ema_window': 20, #RPE\n",
        "    'tc_dps': 20,     #pred_decay\n",
        "    'dps_factor': 20, #pred_decay, #RPE\n",
        "    }\n",
        "\n",
        "### Spike clamping (baseline activity)\n",
        "main_n_neurons = network_hparams['n_channels'] * compute_size(network_hparams['crop_size'], network_hparams['filter_size'], network_hparams['stride'])\\\n",
        "* compute_size(network_hparams['crop_size'], network_hparams['filter_size'], network_hparams['stride'])\n",
        "clamp = {}\n",
        "if clamping_intensity is not None:\n",
        "    encoder = PoissonEncoder(time=network_hparams['time'], dt=network_hparams['dt'])\n",
        "    clamp['output'] = encoder.enc(datum = torch.ones(n_neurons)*clamping_intensity, time=network_hparams['time'], dt=network_hparams['dt'])\n",
        "\n",
        "network_hparams['clamp'] = clamp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rz1wmKKYuVg"
      },
      "source": [
        "time = 400\n",
        "network_hparams.update(\n",
        "    {\n",
        "     'time': time,\n",
        "    }\n",
        ")\n",
        "dataloader, val_loader = load_datasets(network_hparams, data_hparams, mask, mask_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SokdidkrV2Z5"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Venb2KhSYrT_"
      },
      "source": [
        "if network_hparams['save_path'] :\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IavVVHrvYVoI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877,
          "referenced_widgets": [
            "d1a8f2a1ea4b4b7ba8717c0e59110340",
            "99ea60825cc8495e9bd3bb767984987e",
            "53482b02c91243699457c00876b6a778",
            "801c0e012ced447183dbe62088f1064d",
            "50d47f86dc024cc3a24f65298193198c",
            "5d0561ec63e543f59a6603233d48e028",
            "8d3b6295aa07493f98ff998ab07f2cd9",
            "5679585dce9f49d38cad4a4d137ba486",
            "7949caa98fe449f6befcb1e071324f10",
            "3ec345e1a9b5467f9752922cd40b2e00",
            "8d106fed4d2f4a5e80126a178fff1d3e"
          ]
        },
        "outputId": "0e6448a3-ef7f-46d6-fbd8-2dde7a182762"
      },
      "source": [
        "manual_seed(SEED)\n",
        "hparams = {**reward_hparams, **network_hparams, **train_hparams, **data_hparams}\n",
        "net = LCNet(**hparams, reward_fn = DynamicDopamineInjection)\n",
        "net.fit(dataloader = dataloader, val_loader = val_loader, reward_hparams = reward_hparams, **train_hparams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Previous model not found! Training from the beginning...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1a8f2a1ea4b4b7ba8717c0e59110340",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "*validation: output tensor([239, 243, 243, 233, 235, 242, 235, 231, 233, 242]) predicted_label: 1 GT: 3"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*validation: output tensor([173, 156, 128, 163, 172, 161, 159, 179, 174, 161]) predicted_label: 7 GT: 1"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b6b32069759b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mreward_hparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnetwork_hparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_hparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdata_hparams\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLCNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDynamicDopamineInjection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_hparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward_hparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_hparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-8a2164c79bb6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataloader, val_loader, reward_hparams, hparams, online_validate, n_train, n_test, n_val, val_interval, running_window_length, verbose)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0monline_validate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mval_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m                 \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_window_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m                 \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mtrain_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-8a2164c79bb6>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, val_loader, n_val, val_interval, running_window_length)\u001b[0m\n\u001b[1;32m    491\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mreward_hparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                     \u001b[0mtrue_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                     \u001b[0mdopaminergic_layers\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdopaminergic_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                      )\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# Add to spikes recording.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bindsnet/network/network.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, inputs, time, one_step, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mcurrent_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mone_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                 \u001b[0mcurrent_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bindsnet/network/network.py\u001b[0m in \u001b[0;36m_get_inputs\u001b[0;34m(self, layers)\u001b[0m\n\u001b[1;32m    260\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                     \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bindsnet/network/topology.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    638\u001b[0m         a_post = (\n\u001b[1;32m    639\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m         )\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma_post\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNJURL35NEcu"
      },
      "source": [
        "Plots : \n",
        "1. plot_ET (STDP and MSTDPEt) [Check Bindsnet]\n",
        "2. plot feature mapse [bindsnet]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkz7skWaiWj7"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAKGbShj7kOM"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXv13w317oW7"
      },
      "source": [
        "%tensorboard --logdir '/content/runs'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGe49P4-q9zp"
      },
      "source": [
        "## Save/Load Sessions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ow_r8C5qzwu"
      },
      "source": [
        "Save tensorBoard Session "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdHDClhIqUlW"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp -a /content/runs/. /content/drive/MyDrive/LCNet/logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NOgZCamq4p-"
      },
      "source": [
        "Read Saved Sessions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlItthjkq4S5"
      },
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/LCNet/logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZtdOQm4oAu1"
      },
      "source": [
        "# Optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcLDxcrwithj"
      },
      "source": [
        "install and import optuna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGik9_MeQfaI"
      },
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsM-Y9CZiv15"
      },
      "source": [
        "Define objective function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj_n_rwWDrdV"
      },
      "source": [
        "STUDY_NAME  = ''\n",
        "DATA_PATH = ''\n",
        "N_TRIALS = ''\n",
        "\n",
        "def objective(trial):\n",
        "    ### Suggest parameters: \n",
        "    num_layers = trial.suggest_int('Number of Layers', 1, 4)\n",
        "    dropout_rate  = trial.suggest_float('Dropout', 0, .99)\n",
        "    activation = trial.suggest_categorical('activation', ['relu', 'selu', 'sigmoid', 'elu'])\n",
        "    lr = trial.suggest_float('Learning rate', 1e-6, 1)\n",
        "    network_hparams.update({\n",
        "        \n",
        "    })\n",
        "    ###Define your model\n",
        "    manual_seed(SEED)\n",
        "    hparams = {**reward_hparams, **network_hparams, **train_hparams, **data_hparams}\n",
        "    net = LCNet(**hparams, reward_fn = DynamicDopamineInjection)\n",
        "    va_acc = net.fit(dataloader = dataloader, val_loader = val_loader, reward_hparams = reward_hparams, **train_hparams)\n",
        "    ### Define objective value\n",
        "    objective_value = min(va_acc)\n",
        "\n",
        "    \n",
        "    return objective_value\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywzhxB84jthL"
      },
      "source": [
        "Run the study"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDFttXEkjv4f"
      },
      "source": [
        "study = optuna.create_study(study_name = STUDY_NAME , storage=f\"sqlite:////content/drive/MyDrive/LCNet/optuna/optuna_study.db\", load_if_exists=True)\n",
        "study.optimize(objective, n_trials=N_TRIALS )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azp25HveO77U",
        "outputId": "5fdaa0eb-5888-4acd-acdb-d059bfcd5b87"
      },
      "source": [
        "study.best_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dropout': 0.09142336347778651,\n",
              " 'Layer 1': 82,\n",
              " 'Layer 2': 508,\n",
              " 'Layer 3': 286,\n",
              " 'Learning rate': 0.008771184760927113,\n",
              " 'Number of Layers': 3,\n",
              " 'activation': 'relu',\n",
              " 'l1': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epsdhrYujy4f"
      },
      "source": [
        "Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "lYgaOQZBaPJk",
        "outputId": "4cc05a5d-636a-4fa0-e260-cecd4b73845a"
      },
      "source": [
        "plot_parallel_coordinate(study, params=[\"Learning rate\", \"Number of Layers\", \"Dropout\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"4da333a4-edd7-4ced-a4de-49a20b8ed5f8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"4da333a4-edd7-4ced-a4de-49a20b8ed5f8\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '4da333a4-edd7-4ced-a4de-49a20b8ed5f8',\n",
              "                        [{\"dimensions\": [{\"label\": \"Objective Value\", \"range\": [1.2982209920883179, 14561242.0], \"values\": [3.41186261177063, 3.41186261177063, 1573.8834228515625, 40182.33984375, 1528.2066650390625, 3.41186261177063, 5028653.5, 1902.826171875, 4562251.5, 945.5894165039062, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.5610835552215576, 1.2982209920883179, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1996253.125, 3.41186261177063, 1.3412549495697021, 3.41186261177063, 1.3456010818481445, 208.45639038085938, 1.3210997581481934, 3.41186261177063, 1.6091002225875854, 1.3304294347763062, 297.8522033691406, 1.4888664484024048, 1.4887771606445312, 1.3360676765441895, 1.3630410432815552, 3.41186261177063, 1.6488354206085205, 1.3287392854690552, 1.4895340204238892, 3.41186261177063, 3.41186261177063, 1.5344265699386597, 3.41186261177063, 3.41186261177063, 1.440764307975769, 1.488864779472351, 1.488818883895874, 1.466086745262146, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3408962488174438, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3349838256835938, 3.41186261177063, 7.432951927185059, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3247721195220947, 1.4888302087783813, 1.322178602218628, 1.4888978004455566, 1.4888209104537964, 3.41186261177063, 2.3582754135131836, 1.3386236429214478, 3.41186261177063, 1.49014151096344, 1.488823652267456, 3.41186261177063, 1.3245543241500854, 1.323976993560791, 1.4888335466384888, 3.41186261177063, 3.9560186862945557, 3.41186261177063, 2.909315347671509, 1.3193601369857788, 3.41186261177063, 1.511308193206787, 1.3136441707611084, 3.41186261177063, 3.41186261177063, 1.4888402223587036, 1.4888317584991455, 3.41186261177063, 3.41186261177063, 1.3589725494384766, 2.0364224910736084, 3.41186261177063, 1.3351562023162842, 1.333082675933838, 3.41186261177063, 1.345519781112671, 3.41186261177063, 3.41186261177063, 1.3363773822784424, 3.41186261177063, 1.3386261463165283, 3.41186261177063, 1.3352710008621216, 1.4969419240951538, 3.41186261177063, 1.3299638032913208, 1.4888179302215576, 499.7135009765625, 1.488878846168518, 1.4904865026474, 1.3302356004714966, 1.3491047620773315, 3.41186261177063, 1.3281259536743164, 1.4885554313659668, 1.4888970851898193, 3.41186261177063, 1.34572434425354, 1.3183053731918335, 1.4915050268173218, 3.41186261177063, 1.490088939666748, 1.4888391494750977, 1.3113908767700195, 3.41186261177063, 2.1569273471832275, 1.325134038925171, 1.4888319969177246, 3.41186261177063, 2.6820173263549805, 1.4889917373657227, 1.3089126348495483, 1.308632254600525, 3.41186261177063, 1.4888687133789062, 1.3131179809570312, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.4888315200805664, 1.4690502882003784, 1.5091662406921387, 1.3258752822875977, 3.41186261177063, 1.4888314008712769, 1.4705278873443604, 4818.158203125, 1.488825798034668, 1.484520673751831, 3.41186261177063, 1.48581063747406, 1.4793022871017456, 3.41186261177063, 2.6853699684143066, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.5001596212387085, 1.3194295167922974, 1.327432632446289, 1.3218836784362793, 1.3434199094772339, 3.41186261177063, 1.3185940980911255, 1.4976372718811035, 1.3232676982879639, 3.41186261177063, 3.41186261177063, 1.315920352935791, 3.41186261177063, 3.41186261177063, 1.3266558647155762, 3.41186261177063, 1.3477894067764282, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.4888219833374023, 1.373160719871521, 1.3271931409835815, 3.41186261177063, 1.4715697765350342, 1.3213223218917847, 3.41186261177063, 1.308161973953247, 1.4888219833374023, 1.488818645477295, 1.4889020919799805, 1.4888558387756348, 2.69138503074646, 1.3204686641693115, 1.3125131130218506, 3.41186261177063, 1.4888322353363037, 1.3331835269927979, 415.56671142578125, 1.581402063369751, 3.41186261177063, 1.3211685419082642, 1.3021266460418701, 1.4888198375701904, 1.325307011604309, 1.329646110534668, 1.4888436794281006, 1.3281971216201782, 1.4888861179351807, 3.41186261177063, 1.305359959602356, 1.3265137672424316, 1.3640973567962646, 1.3347446918487549, 3.41186261177063, 1.3504081964492798, 1.3332096338272095, 3.41186261177063, 1.4888545274734497, 3.4115991592407227, 3.41186261177063, 3.41186261177063, 1.3193230628967285, 1.4888228178024292, 1.3274098634719849, 1.3126106262207031, 1.3173880577087402, 1.3275312185287476, 1.322373628616333, 1.489281415939331, 3.41186261177063, 1.310310959815979, 1.4888172149658203, 1.3176379203796387, 3.41186261177063, 3.41186261177063, 1.329596757888794, 1.32630455493927, 2.0398926734924316, 1.488019585609436, 1.3448506593704224, 1.48855721950531, 1.4942303895950317, 1.4888358116149902, 311.04400634765625, 1.3175146579742432, 1.3329596519470215, 1.488847255706787, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.4967288970947266, 1.4313173294067383, 1.4887478351593018, 3.41186261177063, 1.8477803468704224, 1.4888261556625366, 1.4888958930969238, 1.3229091167449951, 1.332504153251648, 1.3610163927078247, 3.41186261177063, 1.3288545608520508, 1.3301451206207275, 3.41186261177063, 3.41186261177063, 1.4888267517089844, 3.41186261177063, 3.4117937088012695, 1.3516267538070679, 1.3335763216018677, 3.41186261177063, 199.16970825195312, 1.489451289176941, 1.3276795148849487, 1.334709882736206, 1.3188152313232422, 3.41186261177063, 3.41186261177063, 1.3202966451644897, 1.3358441591262817, 3.41186261177063, 1.4888269901275635, 3.41186261177063, 1.3066781759262085, 3.41186261177063, 1.3137255907058716, 3.41186261177063, 3.41186261177063, 1.3406171798706055, 3.41186261177063, 1.2999054193496704, 1.3272432088851929, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3045551776885986, 3.41186261177063, 1.4952431917190552, 2675.79052734375, 1.3019428253173828, 1.48887038230896, 1.3364481925964355, 1.32117760181427, 3.41186261177063, 1.3121179342269897, 3.41186261177063, 1.4888906478881836, 3.41186261177063, 1.3226450681686401, 3.41186261177063, 1.4888287782669067, 1.320836067199707, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3085274696350098, 1.3093986511230469, 3.41186261177063, 1.488820195198059, 1.317246675491333, 1.4921292066574097, 1.326299786567688, 1.3326469659805298, 3.41186261177063, 1.488829255104065, 3.41186261177063, 1.3266675472259521, 1.491834282875061, 1.3059812784194946, 3.41186261177063, 696.8388061523438, 1.4321969747543335, 1.4888207912445068, 3.41186261177063, 1.311875820159912, 3.41186261177063, 1.3288514614105225, 1.3099689483642578, 1.313618540763855, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.488821268081665, 1.3155453205108643, 3.411557912826538, 3.41186261177063, 1.3217459917068481, 3.41186261177063, 1.4906315803527832, 3.41186261177063, 1.3453859090805054, 1.4888182878494263, 3.41186261177063, 1.314800500869751, 3.41186261177063, 1.3281633853912354, 3.41186261177063, 1.321211814880371, 1102.6551513671875, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3377939462661743, 3.41186261177063, 3.41186261177063, 1.3136341571807861, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3284739255905151, 3.41186261177063, 1.3212107419967651, 1.3475548028945923, 3.41186261177063, 3.41186261177063, 1.3276013135910034, 3.41186261177063, 1.3147908449172974, 1.4900482892990112, 1.4910539388656616, 1.4888460636138916, 1.3363206386566162, 3.41186261177063, 3.41186261177063, 1.4887561798095703, 1.3011691570281982, 57.89400863647461, 3.41186261177063, 3.41186261177063, 2.024686813354492, 1.4956120252609253, 1.4888505935668945, 1.488817572593689, 1.4888553619384766, 1.3047354221343994, 3.41186261177063, 1.488818645477295, 1.3213609457015991, 2.043469190597534, 1.3281235694885254, 1.3031138181686401, 1.4892010688781738, 14561242.0, 3.41186261177063, 1.2996032238006592, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.488633155822754, 3.41186261177063, 1.488843560218811, 1.4442107677459717, 1.415286660194397, 3.41186261177063, 1.4373067617416382, 3181.039794921875, 3.41186261177063, 3.41186261177063, 1.3226823806762695, 1.3124511241912842, 1.3017604351043701, 3.41186261177063, 1.6777530908584595, 1.4891026020050049, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3141649961471558, 3.41186261177063, 3.41186261177063, 1.3052650690078735, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.4536466598510742, 1.3093748092651367, 1.316675066947937, 3.41186261177063, 3.41186261177063, 1.313673973083496, 4.355731964111328, 3.41186261177063, 3.41186261177063, 1.319928765296936, 3.41186261177063, 1.4888230562210083, 1.3414974212646484, 3.41186261177063, 1.488836646080017, 3.41186261177063, 2.672865629196167, 3.41186261177063, 3.41186261177063, 1.4835532903671265, 3.41186261177063, 1.3185737133026123, 1.503530740737915, 1.4888479709625244, 1.3155088424682617, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 2.0430803298950195, 1.3163092136383057, 3.41186261177063, 1.492780327796936, 3.41186261177063, 1.4853918552398682, 1.3153973817825317, 226.0158233642578]}, {\"label\": \"Dropout\", \"range\": [3.443103036387257e-05, 0.9842606560857956], \"values\": [0.18977214464009692, 0.7227315480926801, 0.6815362495608449, 0.5185686676008853, 0.9571123927309707, 0.9413976023486653, 0.9240297064647457, 0.8832423793421973, 0.24820480999218064, 0.22803488983480102, 0.03705698311217703, 0.6687979784843106, 0.2995763177694883, 0.013776342616227705, 0.7506263336085158, 0.46831020858962125, 0.4699295907735423, 0.7784624726260249, 0.126345073419686, 0.4033925539510268, 0.8100547663369849, 0.11997535769142222, 0.34517494036659885, 0.5609482806976116, 0.12266602597561153, 0.14107593864823564, 0.5710514219566252, 0.5784965594320876, 0.09142336347778651, 0.6032814544493361, 0.39142095676496175, 0.5769203239656192, 0.6516745218245438, 0.4028877538782995, 0.5187279938991173, 0.2042794916392674, 0.8247660706030391, 0.06986220574368689, 0.32785661170132746, 0.2983801710400664, 0.19267254632572553, 0.5191530269533787, 0.06790657486476076, 0.0912079503768097, 0.004813769026088974, 0.02323644800214135, 0.05801799181828775, 0.06654630194044663, 0.1666155407376949, 0.021752858239725212, 0.020394699664888126, 0.06269230669812192, 0.054764765785951214, 0.003260979031988895, 0.0010386661049646946, 0.0042514240575314555, 0.25692568926512044, 0.1046480091242594, 0.0936971406943859, 0.1593576837933141, 0.10060409892962652, 0.039881893955648826, 0.009131805200186065, 0.15825048489742177, 0.22795929224033357, 0.10328946678074592, 0.042645892947305065, 0.1300934156651391, 0.08137342020826593, 0.03255850397317858, 0.0032687211019654383, 0.0054011288573812795, 0.9842606560857956, 0.05241566677384037, 0.002022585909989674, 0.11208759600690653, 0.1178981600381534, 0.17176756453516412, 0.14382620352860775, 0.08002638436773904, 0.21665627576686247, 0.03430415450884129, 0.10863876962768966, 0.030115227553549145, 0.03588715693992984, 0.13729906518175178, 0.029199815203026433, 0.07966638871111814, 0.051836270847720585, 0.1906048350017894, 0.052127455144741465, 0.021879004551463396, 0.10722345283414045, 0.07211031931240228, 0.07263815083250716, 0.08682192217721761, 0.14274896340832918, 0.25978152456704495, 0.17556005013273301, 0.06500372738241907, 0.11079873774496185, 0.12166532010138775, 0.07666670846091683, 0.09294591114907316, 0.09945427922991029, 0.1436334728930368, 0.11745473975062676, 0.045141366801021654, 0.15738204180492116, 0.06396837828601888, 0.20450263253346906, 0.029951649004927874, 0.08539379720540134, 0.09754246888896347, 0.0944676340805405, 0.12790599888765714, 0.17946120846687202, 0.06368394847934356, 0.10661137990586715, 0.03718775312778729, 0.14924491872609683, 0.0930492261823937, 0.07439242994802123, 0.017260289893501327, 0.11763801390512933, 0.053661581396183974, 0.0927608235226057, 0.021326752148343786, 0.13127253890822146, 0.08071128808912653, 0.04747427149672451, 0.09799345728234844, 0.10262951470757437, 0.0739678764097289, 0.0008586693541276641, 0.01183804134064103, 0.0014356267148336547, 0.04224617681712018, 0.06138064527594206, 0.02552558850865591, 0.029606589985803084, 0.08804472738367561, 0.0003866889637423043, 0.05529174990778434, 0.02312440920650563, 0.02317213300112871, 0.03231882679344715, 0.002904293927166124, 0.0699004406403539, 0.00448326943437846, 0.048294424062963706, 0.016547035310487877, 0.0423895536083662, 0.06591671644615017, 0.04538835653479515, 0.07214399480856416, 0.03677882620553821, 0.03734087072507006, 0.0005399644029429574, 0.059174074777862344, 0.02175796750859533, 0.07841378095748251, 0.053676210841932734, 0.1229197435675967, 0.1212336573590234, 0.03153559086610436, 0.004505217805839373, 0.725009661957866, 0.11085439762023731, 0.06613954042567897, 0.15181784187943353, 0.08959052592625524, 0.08553933950919818, 0.045222467191919684, 0.13334769083000425, 0.4274785527106425, 0.0018561014024722964, 0.11252773843343927, 0.06733250397411983, 0.027161499608146324, 0.10145758292584943, 0.09788506936364058, 0.1247132785959726, 0.12205694512388535, 0.13697556034747282, 0.07515658552798707, 0.16493885952892962, 0.08049438235332498, 0.07343802314425626, 0.05568483294249682, 0.08312290232123834, 0.08187119892853142, 0.0441305867191334, 0.10405993300797822, 0.06422543732879281, 0.08608027941409539, 0.032712041482421204, 0.11789450753129224, 0.054165854629040576, 0.07442380720347613, 0.02137283982025037, 0.09518961875538334, 0.10602189156194396, 0.13826071757602598, 0.09823442686458109, 0.06530341290112941, 0.04581060389667832, 0.04519175876333156, 0.03972971749058086, 0.08252547219594705, 0.05757215785254003, 0.017542253050450242, 0.12149509799674728, 0.08553386026934692, 0.9048680751591708, 0.08956478890152726, 0.10137083204218914, 0.07945824023174168, 0.06513631323270413, 0.11092307616006822, 0.13346016050874387, 0.13272779553843028, 0.15843922017900025, 0.13385333797619936, 0.12475726304576015, 0.14592706172323708, 0.11323256323796947, 0.0908648492436995, 0.17597461623511873, 0.07529828749794304, 0.10189731540715245, 0.07109789877878567, 0.0820197012623823, 0.1281669140835429, 0.05465642862289666, 0.09799304431299133, 0.07133513914285625, 0.04672547275949813, 0.11668458465970423, 0.0870997576806521, 0.1431490101425841, 0.03576019658665775, 0.03752225056590631, 0.06184614590715558, 0.0752585503000527, 0.03418688298787724, 0.028634785685719363, 0.04400434385393255, 0.02248668327889719, 0.6325023504316492, 0.04185470251173645, 0.05389071784865134, 0.01784256865428973, 0.012472059314996472, 0.031710234141571106, 0.10390799040205387, 0.05681723822354634, 0.018083139703332547, 0.04340793203611792, 0.12099615126762288, 0.0012123950881871778, 0.09170236089458397, 0.07608627310921343, 0.06127578605141091, 0.1567887120342379, 0.15891195945698844, 0.038027575480039065, 0.10569912999577061, 0.058821226644631804, 0.14192372318087684, 0.3299064064086893, 0.08343104793506871, 0.02090251344093779, 0.0950415427466656, 0.5479339359027675, 0.06968289443677259, 0.04141827732751504, 0.000570584848104308, 0.10667096602486088, 0.19867047307767022, 0.13372486375023235, 0.052135849328373465, 0.0757173600579813, 0.2801135965972183, 0.030400900258563793, 0.11669726830065223, 0.08888725177314286, 0.016802875622266136, 0.05365730544446178, 0.07244109470701623, 0.37650259095448346, 0.09801232034917286, 0.1628413870155264, 0.034998878722532795, 0.11992200423695587, 0.06550405288064576, 0.04920234409864489, 0.003958329431651572, 0.06687416246866033, 0.05910665840408718, 0.02493245797214909, 0.07433863608415064, 0.04179387385129526, 0.06272949249072046, 0.07066471139078256, 0.06128176727489264, 0.014397822761264672, 0.04840784470298225, 0.06270251023692296, 0.03145252895786916, 0.08512320118211228, 0.08854798734239794, 0.8297435221086382, 0.0785216394512167, 0.04333047541430265, 0.4724268717765803, 0.0009237965290651851, 0.08490152125501811, 0.022325420161716954, 0.000352831704061439, 0.025808108443689103, 0.014253689149947492, 0.04437567788810526, 0.03702159236130973, 0.04891078828951246, 0.0009908864628801264, 0.022743874061923835, 0.05032228725377848, 0.061126731743288545, 0.05686315826836345, 0.03940061074414607, 0.02031842201071487, 0.06445085997902945, 0.04941282659282947, 0.07587288075369919, 0.020373090270359297, 0.055735997777530466, 0.08144651789480722, 0.0010050816382745596, 0.002013508468486122, 0.011344956028949409, 0.016326901982388106, 0.003381909491668025, 0.002376789144923369, 0.002984806271809526, 0.0011421540830595135, 0.03227896870373849, 0.0009872263847036586, 0.03522150530904351, 0.001876648751473811, 0.04001681354483606, 0.021935589587147992, 3.443103036387257e-05, 0.042409908491311314, 0.025450163349166152, 0.05528613418275456, 0.08950520367959361, 0.048265256860903286, 0.039971750010183216, 0.05640397313179488, 0.021004433926737603, 0.018804511153529522, 0.015989226938690374, 0.06596196265485539, 0.02587192434132664, 0.04500901802784196, 0.07739932405569355, 0.06463783888795176, 0.020056198767562535, 0.04917553285352942, 0.09232545137122536, 9.842401400229905e-05, 0.07688283093582121, 0.03289452352740781, 0.05624996911429003, 0.024305966166802737, 0.06811483876267768, 0.04238046169427501, 0.058885905732796534, 0.01981289662822524, 0.10214356163140752, 0.0017185422089690703, 0.06968508743339868, 0.036604449942349696, 0.045933276655229886, 0.07638778300457917, 0.015757393540010906, 0.09899664650449055, 0.0637614071795838, 0.050714498049248775, 0.031318824294545966, 5.007173838544876e-05, 0.08946034190501388, 0.05607111165610284, 0.022349163411206813, 0.03905149746434803, 0.08660342712761897, 0.059894605248555215, 0.017814331642879374, 0.03757389881530937, 0.07555184794795243, 0.001866192684735056, 0.10998387119941301, 0.0011387396109528401, 0.058582094842012634, 0.03543870089805992, 0.09529616866559847, 0.0003891799634519015, 0.07198127252807866, 0.0890584912244459, 0.07514843271206964, 0.04774444513644024, 0.021697666052363698, 0.10883006504940862, 0.048608302421363256, 0.07958706506048667, 0.02324236591884332, 0.06771101378015973, 0.06182776442907803, 0.03137438983428246, 0.048191754701293596, 0.012192317766585671, 0.06858913642686684, 0.037114301624740054, 0.01758311538438813, 0.03714380589765104, 0.0026554761408616664, 0.03136617361625645, 0.04279455899101382, 0.03821089413613963, 0.06069461393902334, 0.08263154256148016, 0.028886985625439437, 0.04715867084502808, 0.0141401258317767, 0.07004922161202476, 0.09811309445403787, 0.04707526852334387, 0.030903027061292408, 0.07622066265338005, 0.0018572433475626815, 0.0556359041156962, 0.10427322445950628, 0.026994069431266598, 0.004155113356530498, 0.0031013235196995434, 0.43156161185613384, 0.01555485328852984, 0.021914683417306718, 0.9805178380869909, 0.0030231885615408065, 0.028413741785973626, 0.003281262951288888, 0.03720104005601631, 0.003674994388898021, 0.00261923990754568, 0.0029676245113087266, 0.017906656339263374, 0.2452523315804691, 0.67708770503428, 0.02612417283916115, 0.04531049066974576, 0.004637315543127127, 0.013526854482325155, 0.0030398571876038265, 0.003935793273641438, 0.00011147460648451915, 0.04784672934459856, 0.0009924063792427773, 0.0308750336739222, 0.053919319575250646, 0.0013838864553914962, 0.02260437815196577, 0.04290171639333729, 0.0005994551596217451, 0.06215828032759168, 0.031406293072650436, 0.05779459070988171, 0.01615746453546504, 0.03916746309493418, 0.771355916526557, 0.0004434535661207023, 0.059683995693768616, 0.07609962368472586, 0.024391975533022945, 0.045078353997614784, 0.06986488665283336, 0.0214930933921556, 0.04285829518180141, 0.01877261375194468, 0.08699617281962638, 0.05547172468515345, 0.00047376795584941627, 0.0001956695935350361, 0.03798531711097779, 0.06870642092035026, 0.1035445891095131, 0.027148385411983125, 0.08649193502290965, 0.050004943961580686]}, {\"label\": \"Learning rate\", \"range\": [4.839092386705679e-06, 0.999345881690639], \"values\": [0.8318111488629595, 0.5825190685066907, 0.8026175082579672, 0.6970440623810661, 0.3718848814571064, 0.9194361419958322, 0.6203094078517274, 0.3552388697724913, 0.4276298249589038, 0.044580280884625914, 0.970940037395826, 0.5901029835471306, 0.7850291054202887, 0.1880601162630498, 0.8490109726052444, 0.5085890263628017, 0.6660617866540687, 0.8839902023100054, 0.21539453881286114, 0.7132230699402093, 0.9635280722837865, 0.23701479130654213, 0.7573731362385578, 0.999345881690639, 0.009805414827726844, 0.2262018768767552, 0.9939229598154355, 0.0005647326270766251, 0.008771184760927113, 0.13746334034929766, 0.11510997037238159, 0.04088806407666547, 0.08345094274377901, 0.11652154408979622, 0.2988501763969884, 0.7274573603250489, 0.9008562366485751, 0.2956187496041139, 0.520493928904637, 0.4401003119778594, 0.8072312699347531, 0.819573894354146, 0.0038562530732292755, 0.02868917334823695, 0.0066328812289193195, 0.010777294021001433, 0.0005026089887436532, 0.07018339557195341, 0.1569976610569958, 0.00011998139166572927, 0.07489030743527873, 0.05119949949940067, 0.06472811371731842, 0.003638930111458142, 0.002799875313480671, 0.1702828572315992, 0.09863628535301724, 7.536833608501325e-05, 0.13638142118669183, 0.03748671413913193, 0.18197735102681784, 0.006575684098518466, 0.033976745180029404, 0.1093242513307107, 0.0015533218647126464, 0.08255258339830071, 0.046648239428554956, 0.006117449112957771, 0.13736961307686082, 0.20678274872244926, 0.26072449645801843, 0.001804019407857957, 0.020667049747028265, 0.060973332016613924, 0.09894953059915138, 0.005009273284468599, 0.040869575211491926, 0.0005106437167951795, 0.08807903074181601, 0.12923208540114764, 0.06318368476551045, 0.00046545414732343873, 0.025326689619468153, 0.000836307857516224, 0.04682815809985486, 0.026096937838657575, 0.0821556605848515, 0.15404082948907472, 0.0004609839602319583, 0.37780178166151307, 0.10601748847672118, 0.024195652321651488, 0.06559479895703142, 0.0008278344577075933, 0.0006263382346023283, 0.04231944383144484, 0.6199098957578392, 0.02517602266172283, 0.05407579592812331, 0.08584897176475585, 0.00018656772848294379, 0.024198028745843078, 0.004503205451593816, 0.0004392748746655684, 0.05903817570064794, 0.5447735247632177, 0.04249084884283121, 0.022016121675431093, 0.11615508888831637, 0.07165078331223045, 0.003171236616504612, 0.020937086021157927, 0.04145644212433934, 0.00034831258999738074, 0.00024867633838791846, 0.05758447226199979, 1.530797035000437e-05, 0.09704370650534337, 0.022151707558353245, 0.00018962612560447894, 0.04204894309009263, 0.0027952489288840692, 0.0761684118992445, 0.000114276094693333, 0.021772036018191675, 0.038849786038969394, 0.0006001452444256708, 0.051978477563983494, 0.02013727253005528, 0.07358177466113344, 0.4467724084884145, 0.0032833509140603716, 7.09956810860733e-05, 0.03255131223512051, 3.606647282256226e-05, 0.05569446607220057, 0.021049024507253326, 0.03485501080228253, 9.469444130095345e-05, 0.00042076570458325906, 0.09062881811017992, 0.015945012116275574, 0.05993098579073255, 0.013570053587776267, 0.0015964858632057878, 0.03361534081065006, 0.04531106303592312, 0.0024510427688730465, 0.015831034405731706, 0.0716349585074928, 0.0016152111930970562, 0.03299261525432884, 0.00039750005293959315, 0.0003735123694220152, 0.022954684835970445, 0.05030750834425449, 0.0019456392138276438, 0.03636853045826222, 0.017641678995441265, 0.05553940340159806, 0.017740118481972378, 0.0018485961636392208, 0.003644648238668417, 0.0008905678352506823, 0.027921368867372797, 0.0425612233853034, 0.0017823998823285313, 0.07314653593250144, 0.021350698054067366, 0.0014578074201163668, 0.6869616904774993, 0.0018174574296485665, 0.00254190704159633, 0.04786929311322935, 0.0011421035682364898, 0.03194497537763594, 0.01909453388600864, 0.059908197211907266, 0.03340643650992153, 0.002560702283418414, 0.00047973318343545566, 3.428312596082551e-05, 0.0002621838796837353, 0.0006848323529311741, 0.019987745225089337, 0.0010200128772356876, 0.03606771370723579, 0.0002110597233802087, 0.020449786947493095, 0.05139164646076383, 0.0002768828002315304, 0.018231075948590064, 0.8672271619313537, 0.00025975098994360685, 0.03391207657075111, 0.0014886727804582435, 0.0185633767611625, 0.7767051575038381, 0.04092783700242046, 0.01732202128809746, 4.839092386705679e-06, 9.250249068863388e-05, 0.9468883072631986, 0.0013709578451224268, 0.000299448190639499, 0.02583869534986426, 0.0006589696904070356, 0.04738346334479894, 0.02034327834590992, 0.06475412429969495, 0.02006078515589438, 0.0038582777392556318, 0.00038058179938438763, 0.00044436504219958324, 0.03516725854281543, 0.01886451605024933, 0.0007141120682533505, 0.03399878985704272, 0.32670260609012014, 0.018343659424244783, 0.00021620854488433282, 0.019600361830822803, 0.015829874656146214, 0.002042446018317671, 0.001380493285773636, 0.04287775883688133, 0.0018594929095926919, 0.03304388215031253, 0.0176194148353488, 0.0019793001043673887, 0.0002234535250527764, 3.8187742437063805e-05, 0.00018275630908954593, 0.021243757037771104, 0.0005455542353190162, 0.00017461130867614476, 0.03854773589447761, 0.020835541184319396, 0.054227922207086734, 0.019837023419036204, 0.03570054537482614, 0.002664028966735375, 0.014622896166524818, 6.190764292296827e-05, 0.0020020589569840286, 0.0007428723574550438, 0.0010230302497837957, 0.0006402148287644081, 0.026947944878872445, 0.019591669722353232, 0.0006354729643167035, 0.04701484324177392, 0.001116046081058396, 0.020961850118742326, 0.03701763274370863, 0.00036125055463698697, 0.0009983878913666319, 0.01991791248581757, 0.057140131629773515, 6.490671006018837e-05, 0.03477775045206333, 0.40535723770474574, 0.018391357944358925, 0.017468259895893963, 1.6337379373740162e-05, 2.4275611411332405e-05, 0.04521134143996523, 0.03199729110331968, 0.06521636725184048, 0.017195208942716606, 0.0004852933705535605, 0.0015605175032298198, 0.03468196537957979, 0.2618252677392967, 0.0007734925840008856, 0.018525261947555407, 0.051289532775630066, 0.01875266703501147, 0.0006428107515578265, 0.0002969712375334517, 0.040156271154686105, 0.0005272010903337764, 9.923612903044296e-06, 0.4924530550230862, 0.031011174052843374, 0.019160568953309098, 0.0723802758494964, 0.05171238602106266, 0.018757726276329795, 0.0008900266959972472, 0.03289050004766596, 0.018820792078667818, 0.04100349661200286, 0.0011935629447178597, 0.0009347307225850039, 0.0008078155709304219, 0.02124873032076251, 0.06241904138094003, 0.00041781949424815374, 8.136484272236368e-05, 0.03553173899429297, 0.017727684254190853, 0.04845224030298898, 0.0006769261764987614, 0.638178433448891, 0.0005457508688992035, 0.019435548164763845, 0.03056704540699154, 7.508419154701003e-05, 0.08578648864135227, 0.0008819475400870596, 0.0003304492161692224, 0.020681782488756708, 0.05445371224659366, 0.03416892717068001, 0.02134166362153642, 0.01685350843413476, 0.041022072288961056, 0.0005759146007853044, 0.018336859269085407, 0.0008982257708812491, 0.06768937612732671, 0.0010533713867024353, 0.03938048426744762, 0.0008266021528289115, 0.0010448501238005006, 0.018145010853096565, 0.0002995882361112422, 0.05231516839949336, 0.032392650945967924, 0.01702546991488874, 0.0002942316335957289, 0.03474450766041615, 0.015348776662527364, 0.00027269847933289297, 0.0536858079070212, 0.01976538618810699, 0.036087164878083625, 0.0002827213937042818, 0.0015741200620933435, 0.08012561111167861, 0.017302362980815143, 0.0010400591616107789, 0.5608418405327812, 0.00011304829506689944, 0.00018579677481631713, 0.05230514036084195, 0.02909717629588059, 0.020255502508929196, 6.779688621230283e-05, 0.1979235140215808, 0.0003918360389160052, 0.038234671920108515, 0.0648772575391006, 0.0007414501936795313, 0.019384775180918985, 0.039904104044949956, 0.0006839603038786923, 0.021520193029948394, 0.0011345692354542934, 0.0003523715605829366, 0.00022719604343753762, 0.03400622127657148, 0.0544755872582909, 0.01841942571259952, 0.01585306813913724, 0.000895802241765959, 0.03584010936264005, 0.01995692910962721, 2.8411756343403323e-05, 0.05031701728599021, 0.07296107997361252, 0.016331784333223704, 0.000354943304533424, 0.03656480591031412, 0.01874706391101637, 0.001791009442819385, 0.03520417008345619, 0.0014026435551135446, 0.05579384823640002, 0.00028497881259451486, 0.021223368827225336, 0.09975430421623677, 0.7445915829684586, 0.019701393489866457, 0.00013601067862287642, 0.03945870917402249, 0.4753148348889939, 0.0007064693205584117, 0.01907932192961654, 0.06697944418920354, 0.03508214385987181, 0.0006737979932668642, 0.017025425866391903, 0.0002824027070356082, 0.00014348347017702667, 0.048829640019877885, 0.0311663083412486, 0.0002911588928624626, 0.02058280298567976, 0.00045442284690733604, 0.24101336562042008, 0.048612464298794844, 0.01791757022560716, 1.8929290669759307e-05, 0.35811131174784067, 0.030513876781038347, 0.07172710719984579, 0.0008570216410594862, 0.0005966385127998599, 0.033194357249811964, 0.01834671626233139, 0.0008652467309240649, 0.05712498760706458, 0.03441620914177599, 0.01829768702177668, 0.016715581255036836, 0.00035923209422856263, 0.04692155351938929, 0.016046353024569745, 1.9999299314673452e-05, 0.0012703788445227653, 0.00010034699311291354, 0.0003325753751028354, 0.0863015147371859, 0.8412255140737062, 0.035314435433658004, 0.0003466879198883485, 0.04672437847140255, 0.020598942526623396, 0.03138215277414517, 0.06311656294015146, 0.16915758389571572, 0.018329434307616934, 0.018429149167798732, 0.0009573404116975137, 0.0007279542336458705, 0.045718197314420575, 0.0007698264248074498, 0.033791280109997116, 0.02585155394540583, 0.01693227764988244, 3.351934514526797e-05, 0.0005442495333666092, 0.0005558447602022427, 0.0563074904530597, 0.0008948678738089797, 0.03141200921360738, 0.01826122412017685, 0.0008949051168063129, 0.04784121126826306, 0.0003676829089073754, 0.032389933714145475, 0.018435791521706987, 0.0005704638146096265, 0.9180648957028958, 0.0169190790709879, 0.06689865071678494, 0.039898404950601776, 0.2996709638075558, 0.01652373700233391, 0.001166835769141716, 0.0005462461895284236, 0.0004040484392920495, 0.03640123882483865, 0.08387538940415022, 0.00036652575553067766, 0.0002107701935435868, 0.05422445207145151, 0.021034812640492482, 0.00017804436105929653, 0.03201672624258654, 0.017753273028320728, 0.00015393342061492655, 0.037715444240410415, 0.01944877003370576, 0.05564548384656694, 0.0007176007617984702, 0.01881215232901902, 0.04203171954219195, 0.0004931854463415218, 0.01883012226726168, 0.001030064517039493, 0.12882515770857506, 0.06856564600298082, 0.00040195562967428413, 0.03164688043140422, 0.020057567399541308, 0.04161125333344681, 0.01760584281377843, 0.04574589273977703, 0.020957922666900004, 0.0021496883411404014, 0.001200892996070054, 0.030733631262990193, 0.40917614895591103, 0.06263014898591063, 0.0012013042799923124, 0.00015718333163665399, 0.0192413593080739]}, {\"label\": \"Number of Layers\", \"range\": [1, 4], \"values\": [1, 1, 1, 2, 2, 3, 3, 2, 3, 3, 4, 1, 1, 1, 1, 2, 1, 2, 2, 4, 2, 2, 4, 4, 2, 3, 4, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 2, 3, 2, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 2, 4, 4, 2, 4, 4, 3, 3, 4, 4, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]}], \"labelangle\": 30, \"labelside\": \"bottom\", \"line\": {\"color\": [3.41186261177063, 3.41186261177063, 1573.8834228515625, 40182.33984375, 1528.2066650390625, 3.41186261177063, 5028653.5, 1902.826171875, 4562251.5, 945.5894165039062, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.5610835552215576, 1.2982209920883179, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1996253.125, 3.41186261177063, 1.3412549495697021, 3.41186261177063, 1.3456010818481445, 208.45639038085938, 1.3210997581481934, 3.41186261177063, 1.6091002225875854, 1.3304294347763062, 297.8522033691406, 1.4888664484024048, 1.4887771606445312, 1.3360676765441895, 1.3630410432815552, 3.41186261177063, 1.6488354206085205, 1.3287392854690552, 1.4895340204238892, 3.41186261177063, 3.41186261177063, 1.5344265699386597, 3.41186261177063, 3.41186261177063, 1.440764307975769, 1.488864779472351, 1.488818883895874, 1.466086745262146, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3408962488174438, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3349838256835938, 3.41186261177063, 7.432951927185059, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3247721195220947, 1.4888302087783813, 1.322178602218628, 1.4888978004455566, 1.4888209104537964, 3.41186261177063, 2.3582754135131836, 1.3386236429214478, 3.41186261177063, 1.49014151096344, 1.488823652267456, 3.41186261177063, 1.3245543241500854, 1.323976993560791, 1.4888335466384888, 3.41186261177063, 3.9560186862945557, 3.41186261177063, 2.909315347671509, 1.3193601369857788, 3.41186261177063, 1.511308193206787, 1.3136441707611084, 3.41186261177063, 3.41186261177063, 1.4888402223587036, 1.4888317584991455, 3.41186261177063, 3.41186261177063, 1.3589725494384766, 2.0364224910736084, 3.41186261177063, 1.3351562023162842, 1.333082675933838, 3.41186261177063, 1.345519781112671, 3.41186261177063, 3.41186261177063, 1.3363773822784424, 3.41186261177063, 1.3386261463165283, 3.41186261177063, 1.3352710008621216, 1.4969419240951538, 3.41186261177063, 1.3299638032913208, 1.4888179302215576, 499.7135009765625, 1.488878846168518, 1.4904865026474, 1.3302356004714966, 1.3491047620773315, 3.41186261177063, 1.3281259536743164, 1.4885554313659668, 1.4888970851898193, 3.41186261177063, 1.34572434425354, 1.3183053731918335, 1.4915050268173218, 3.41186261177063, 1.490088939666748, 1.4888391494750977, 1.3113908767700195, 3.41186261177063, 2.1569273471832275, 1.325134038925171, 1.4888319969177246, 3.41186261177063, 2.6820173263549805, 1.4889917373657227, 1.3089126348495483, 1.308632254600525, 3.41186261177063, 1.4888687133789062, 1.3131179809570312, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.4888315200805664, 1.4690502882003784, 1.5091662406921387, 1.3258752822875977, 3.41186261177063, 1.4888314008712769, 1.4705278873443604, 4818.158203125, 1.488825798034668, 1.484520673751831, 3.41186261177063, 1.48581063747406, 1.4793022871017456, 3.41186261177063, 2.6853699684143066, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.5001596212387085, 1.3194295167922974, 1.327432632446289, 1.3218836784362793, 1.3434199094772339, 3.41186261177063, 1.3185940980911255, 1.4976372718811035, 1.3232676982879639, 3.41186261177063, 3.41186261177063, 1.315920352935791, 3.41186261177063, 3.41186261177063, 1.3266558647155762, 3.41186261177063, 1.3477894067764282, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.4888219833374023, 1.373160719871521, 1.3271931409835815, 3.41186261177063, 1.4715697765350342, 1.3213223218917847, 3.41186261177063, 1.308161973953247, 1.4888219833374023, 1.488818645477295, 1.4889020919799805, 1.4888558387756348, 2.69138503074646, 1.3204686641693115, 1.3125131130218506, 3.41186261177063, 1.4888322353363037, 1.3331835269927979, 415.56671142578125, 1.581402063369751, 3.41186261177063, 1.3211685419082642, 1.3021266460418701, 1.4888198375701904, 1.325307011604309, 1.329646110534668, 1.4888436794281006, 1.3281971216201782, 1.4888861179351807, 3.41186261177063, 1.305359959602356, 1.3265137672424316, 1.3640973567962646, 1.3347446918487549, 3.41186261177063, 1.3504081964492798, 1.3332096338272095, 3.41186261177063, 1.4888545274734497, 3.4115991592407227, 3.41186261177063, 3.41186261177063, 1.3193230628967285, 1.4888228178024292, 1.3274098634719849, 1.3126106262207031, 1.3173880577087402, 1.3275312185287476, 1.322373628616333, 1.489281415939331, 3.41186261177063, 1.310310959815979, 1.4888172149658203, 1.3176379203796387, 3.41186261177063, 3.41186261177063, 1.329596757888794, 1.32630455493927, 2.0398926734924316, 1.488019585609436, 1.3448506593704224, 1.48855721950531, 1.4942303895950317, 1.4888358116149902, 311.04400634765625, 1.3175146579742432, 1.3329596519470215, 1.488847255706787, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.4967288970947266, 1.4313173294067383, 1.4887478351593018, 3.41186261177063, 1.8477803468704224, 1.4888261556625366, 1.4888958930969238, 1.3229091167449951, 1.332504153251648, 1.3610163927078247, 3.41186261177063, 1.3288545608520508, 1.3301451206207275, 3.41186261177063, 3.41186261177063, 1.4888267517089844, 3.41186261177063, 3.4117937088012695, 1.3516267538070679, 1.3335763216018677, 3.41186261177063, 199.16970825195312, 1.489451289176941, 1.3276795148849487, 1.334709882736206, 1.3188152313232422, 3.41186261177063, 3.41186261177063, 1.3202966451644897, 1.3358441591262817, 3.41186261177063, 1.4888269901275635, 3.41186261177063, 1.3066781759262085, 3.41186261177063, 1.3137255907058716, 3.41186261177063, 3.41186261177063, 1.3406171798706055, 3.41186261177063, 1.2999054193496704, 1.3272432088851929, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3045551776885986, 3.41186261177063, 1.4952431917190552, 2675.79052734375, 1.3019428253173828, 1.48887038230896, 1.3364481925964355, 1.32117760181427, 3.41186261177063, 1.3121179342269897, 3.41186261177063, 1.4888906478881836, 3.41186261177063, 1.3226450681686401, 3.41186261177063, 1.4888287782669067, 1.320836067199707, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3085274696350098, 1.3093986511230469, 3.41186261177063, 1.488820195198059, 1.317246675491333, 1.4921292066574097, 1.326299786567688, 1.3326469659805298, 3.41186261177063, 1.488829255104065, 3.41186261177063, 1.3266675472259521, 1.491834282875061, 1.3059812784194946, 3.41186261177063, 696.8388061523438, 1.4321969747543335, 1.4888207912445068, 3.41186261177063, 1.311875820159912, 3.41186261177063, 1.3288514614105225, 1.3099689483642578, 1.313618540763855, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.488821268081665, 1.3155453205108643, 3.411557912826538, 3.41186261177063, 1.3217459917068481, 3.41186261177063, 1.4906315803527832, 3.41186261177063, 1.3453859090805054, 1.4888182878494263, 3.41186261177063, 1.314800500869751, 3.41186261177063, 1.3281633853912354, 3.41186261177063, 1.321211814880371, 1102.6551513671875, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3377939462661743, 3.41186261177063, 3.41186261177063, 1.3136341571807861, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3284739255905151, 3.41186261177063, 1.3212107419967651, 1.3475548028945923, 3.41186261177063, 3.41186261177063, 1.3276013135910034, 3.41186261177063, 1.3147908449172974, 1.4900482892990112, 1.4910539388656616, 1.4888460636138916, 1.3363206386566162, 3.41186261177063, 3.41186261177063, 1.4887561798095703, 1.3011691570281982, 57.89400863647461, 3.41186261177063, 3.41186261177063, 2.024686813354492, 1.4956120252609253, 1.4888505935668945, 1.488817572593689, 1.4888553619384766, 1.3047354221343994, 3.41186261177063, 1.488818645477295, 1.3213609457015991, 2.043469190597534, 1.3281235694885254, 1.3031138181686401, 1.4892010688781738, 14561242.0, 3.41186261177063, 1.2996032238006592, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.488633155822754, 3.41186261177063, 1.488843560218811, 1.4442107677459717, 1.415286660194397, 3.41186261177063, 1.4373067617416382, 3181.039794921875, 3.41186261177063, 3.41186261177063, 1.3226823806762695, 1.3124511241912842, 1.3017604351043701, 3.41186261177063, 1.6777530908584595, 1.4891026020050049, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.3141649961471558, 3.41186261177063, 3.41186261177063, 1.3052650690078735, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 1.4536466598510742, 1.3093748092651367, 1.316675066947937, 3.41186261177063, 3.41186261177063, 1.313673973083496, 4.355731964111328, 3.41186261177063, 3.41186261177063, 1.319928765296936, 3.41186261177063, 1.4888230562210083, 1.3414974212646484, 3.41186261177063, 1.488836646080017, 3.41186261177063, 2.672865629196167, 3.41186261177063, 3.41186261177063, 1.4835532903671265, 3.41186261177063, 1.3185737133026123, 1.503530740737915, 1.4888479709625244, 1.3155088424682617, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 3.41186261177063, 2.0430803298950195, 1.3163092136383057, 3.41186261177063, 1.492780327796936, 3.41186261177063, 1.4853918552398682, 1.3153973817825317, 226.0158233642578], \"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"reversescale\": true, \"showscale\": true}, \"type\": \"parcoords\"}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Parallel Coordinate Plot\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4da333a4-edd7-4ced-a4de-49a20b8ed5f8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkmj9tDazbm3"
      },
      "source": [
        "# Plotting the feature maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMyqurrBzez3"
      },
      "source": [
        "dataset_fmaps = MNIST(\n",
        "        PoissonEncoder(time=network_hparams['time'], dt=network_hparams['dt']),\n",
        "        None,\n",
        "        root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda x: x * data_hparams['intensity']),\n",
        "            transforms.CenterCrop(data_hparams['crop_size'])]\n",
        "        ),\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG4EoDKEzexY"
      },
      "source": [
        "indices = dataset_fmaps.targets == 0\n",
        "dataset_fmaps.data, dataset_fmaps.targets = dataset_fmaps.data[indices], dataset_fmaps.targets[indices]\n",
        "\n",
        "idx = 20\n",
        "datum = dataset_fmaps[idx]\n",
        "img = datum[\"image\"][0,:,:]\n",
        "label = datum[\"label\"]\n",
        "enc_img = datum[\"encoded_image\"].to(device)\n",
        "plt.imshow(img, cmap='gray')\n",
        "print('label:', label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkE7zJxizlgb"
      },
      "source": [
        "#print(net.connections[('main', 'output_0')].w.shape)\n",
        "print(net.connections[('input', 'main')].w.shape)\n",
        "print(net.connections[('input', 'main')].mask.shape)\n",
        "print(sum(net.connections[('input', 'main')].mask[:,0] == 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSdD8hPAzm5P"
      },
      "source": [
        "n_filts = (int((network_hparams['crop_size']-network_hparams['filter_size'])/network_hparams['stride'])+1)\n",
        "n_filts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYAtejQAzoku"
      },
      "source": [
        "\n",
        "fmaps = torch.zeros(network_hparams['filter_size'], network_hparams['filter_size'], network_hparams['n_channels'], int((network_hparams['crop_size']-network_hparams['filter_size'])/network_hparams['stride'])+1,\\\n",
        "int((network_hparams['crop_size']-network_hparams['filter_size'])/network_hparams['stride'])+1)\n",
        "print(fmaps.shape)\n",
        "fmaps_full = torch.zeros(network_hparams['filter_size']*network_hparams['filter_size'],network_hparams['n_channels'],(int((network_hparams['crop_size']-network_hparams['filter_size'])/network_hparams['stride'])+1),\\\n",
        "(int((network_hparams['crop_size']-network_hparams['filter_size'])/network_hparams['stride'])+1))\n",
        "print(fmaps_full.shape)\n",
        "\n",
        "reshaped_w = net.connections[('input', 'main')].w.view(network_hparams['crop_size']*network_hparams['crop_size'],network_hparams['n_channels'],(int((network_hparams['crop_size']-network_hparams['filter_size'])/network_hparams['stride'])+1),\\\n",
        "    (int((network_hparams['crop_size']-network_hparams['filter_size'])/network_hparams['stride'])+1))\n",
        "\n",
        "reshaped_msk = net.connections[('input', 'main')].mask.view(network_hparams['crop_size']*network_hparams['crop_size'],network_hparams['n_channels'],(int((network_hparams['crop_size']-network_hparams['filter_size'])/network_hparams['stride'])+1),\\\n",
        "    (int((network_hparams['crop_size']-network_hparams['filter_size'])/network_hparams['stride'])+1))\n",
        "\n",
        "print(reshaped_w.shape, reshaped_msk.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzfSQpaczqHL"
      },
      "source": [
        "for i in range(network_hparams['n_channels']):\n",
        "    for j in range((int((network_hparams['crop_size']-network_hparams['filter_size'])/network_hparams['stride'])+1)):\n",
        "        for k in range((int((network_hparams['crop_size']-network_hparams['filter_size'])/network_hparams['stride'])+1)):\n",
        "            fmaps_full[:,i,j,k] = reshaped_w[reshaped_msk[:,i,j,k]==False, i,j,k]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut7wA1Emzq4J"
      },
      "source": [
        "chan_idx = 20 # 0 to N_channels \n",
        "fig, axs = plt.subplots(n_filts, n_filts)\n",
        "for i in range(n_filts):\n",
        "    for j in range(n_filts):\n",
        "        axs[i][j].imshow(fmaps_full[:,chan_idx,i,j].view(network_hparams['filter_size'],network_hparams['filter_size']), cmap='Greys')\n",
        "        axs[i][j].axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}